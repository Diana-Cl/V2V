name: Scheduled Scrape

on:
  schedule:
    - cron: '0 */4 * * *' # Ù‡Ø± Û´ Ø³Ø§Ø¹Øª ÛŒÚ© Ø¨Ø§Ø± Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯

jobs:
  build-and-commit:
    permissions:
      contents: write
    runs-on: ubuntu-latest
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests # ÙÙ‚Ø· Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ù†ØµØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯

      - name: Run final scraper script
        run: python scraper.py
        env:
          # ÙÙ‚Ø· SecretÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù†Ù‡Ø§ÛŒÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡â€ŒØ§Ù†Ø¯
          GH_PAT: ${{ secrets.GH_PAT }}
          
      - name: Upload final JSON to ArvanCloud Object Storage
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_SECRET_ACCESS_KEY }}
        run: |
          pip install awscli
          # ÙÙ‚Ø· ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯
          aws s3 cp all_live_configs.json s3://v2v-data/all_live_configs.json --endpoint-url https://s3.ir-thr-at1.arvanstorage.com --acl public-read

      - name: Commit and Push the final JSON to GitHub
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ğŸ“Š Update all_live_configs.json (Scheduled)"
          # ÙÙ‚Ø· ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Commit Ù…ÛŒâ€ŒØ´ÙˆØ¯
          file_pattern: "all_live_configs.json"
          branch: main
