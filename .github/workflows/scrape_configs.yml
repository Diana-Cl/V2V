Name: Scheduled Scrape and Build

on:
  schedule:
    # Ù‡Ø± Û¶ Ø³Ø§Ø¹Øª ÛŒÚ© Ø¨Ø§Ø± Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    - cron: '0 */6 * * *'
  workflow_dispatch: # Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒ

jobs:
  build-and-commit:
    permissions:
      contents: write
      # Ø¯Ø³ØªØ±Ø³ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ú©Ø´ (Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒÙ¾Ù„ÙˆÛŒ Ø¬Ø¯ÛŒØ¯)
      pages: write
    runs-on: ubuntu-latest
    timeout-minutes: 45
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: pip install requests PyYAML PyGithub

      - name: Preserve previous clash subscription if it exists
        run: |
          if [ -f "clash_subscription.yaml" ]; then
            mv clash_subscription.yaml clash_subscription.yaml.bak
            echo "Previous clash_subscription.yaml has been backed up."
          fi

      - name: Run scraper script
        run: python scraper.py
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        timeout-minutes: 40
      
      - name: Restore previous clash subscription if scraper did not generate one
        run: |
          if [ ! -f "clash_subscription.yaml" ] && [ -f "clash_subscription.yaml.bak" ]; then
            mv clash_subscription.yaml.bak clash_subscription.yaml
            echo "Scraper did not generate a new clash file. Restored the previous version."
          fi
          
      - name: Upload files to ArvanCloud
        continue-on-error: true
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_ACCESS_KEY_SECRET }}
        run: |
          pip install awscli
          if [ -f "all_live_configs.json" ]; then
            aws s3 cp all_live_configs.json s3://v2v-data/all_live_configs.json --endpoint-url https://s3.ir-thr-at1.arvanstorage.com --acl public-read --cache-control "max-age=300"
          fi
          if [ -f "clash_subscription.yaml" ]; then
            aws s3 cp clash_subscription.yaml s3://v2v-data/clash_subscription.yaml --endpoint-url https://s3.ir-thr-at1.arvanstorage.com --acl public-read --cache-control "max-age=300"
          fi
          if [ -f "index.html" ]; then
            aws s3 cp index.html s3://v2v-data/index.html --endpoint-url https://s3.ir-thr-at1.arvanstorage.com --acl public-read --content-type "text/html" --cache-control "max-age=300"
          fi

      # --- CHANGE 1: A new step to generate a unique version file ---
      - name: Generate Cache Buster Version
        run: echo "$(date +%s)" > cache_version.txt

      - name: Commit and Push the final files to GitHub
        id: commit_step
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add all_live_configs.json || echo "all_live_configs.json not found to commit"
          git add clash_subscription.yaml || echo "clash_subscription.yaml not found to commit"
          # --- CHANGE 2: Add the new version file to the commit ---
          git add cache_version.txt || echo "cache_version.txt not found to commit"
          
          if git diff-index --quiet HEAD; then
            echo "No changes to commit."
            echo "changes_pushed=false" >> $GITHUB_OUTPUT
          else
            git commit -m "ðŸ“Š Update configs [$(date -u)]"
            git push
            echo "changes_pushed=true" >> $GITHUB_OUTPUT
          fi
      
      - name: Purge GitHub Pages Cache by Re-deploying
        if: steps.commit_step.outputs.changes_pushed == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Triggering a new GitHub Pages deployment to purge the cache..."
          gh api --method POST -H "Accept: application/vnd.github+json" /repos/${{ github.repository }}/pages/deployments

