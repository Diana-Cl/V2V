name: Scheduled Scrape

on:
  schedule:
    - cron: '0 */4 * * *'

jobs:
  build-and-commit:
    permissions:
      contents: write
    runs-on: ubuntu-latest
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper script
        run: python scraper.py
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          GITLAB_API_TOKEN: ${{ secrets.GITLAB_API_TOKEN }}
          GITLAB_SNIPPET_ID: ${{ secrets.GITLAB_SNIPPET_ID }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          
      # بخش جدید: آپلود فایل‌ها در ابر آروان
      - name: Upload to ArvanCloud Object Storage
        uses: jakejarvis/s3-sync-action@master
        with:
          args: --acl public-read --follow-symlinks --delete
        env:
          AWS_S3_ENDPOINT: 'https://s3.ir-thr-at1.arvanstorage.com'
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: 'v2v-data'
          SOURCE_DIR: '.'
          DEST_DIR: '/'

      - name: Commit and Push new configs to GitHub
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update config files"
          file_pattern: "*.txt *.yaml"
          branch: main
          push_options: --force
