name: 'V2V Enhanced Publisher - Complete Protocol Coverage'

on:
  schedule:
    - cron: '0 */3 * * *'  # Every 3 hours for optimal freshness
  workflow_dispatch:
  push:
    branches: [ main, master ]
    paths: 
      - 'scraper.py'
      - 'sources.json'
      - '.github/workflows/**'

env:
  WORKFLOW_TIMEOUT_MINUTES: 58
  PYTHON_VERSION: '3.11'

jobs:
  enhanced_scraping:
    runs-on: ubuntu-latest
    environment: Production
    timeout-minutes: 50
    
    outputs:
      configs_updated: ${{ steps.check_changes.outputs.configs_updated }}
      xray_count: ${{ steps.stats.outputs.xray_count }}
      singbox_count: ${{ steps.stats.outputs.singbox_count }}
    
    steps:
    - name: ğŸš€ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
      timeout-minutes: 3

    - name: ğŸ Setup Enhanced Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
      timeout-minutes: 5

    - name: ğŸ“¦ Install Enhanced Dependencies
      run: |
        python -m pip install --upgrade pip wheel setuptools
        pip install requests PyGithub PyYAML urllib3 certifi
        pip install --upgrade requests urllib3  # Ensure latest versions
        echo "âœ… Dependencies installed successfully"
      timeout-minutes: 5

    - name: ğŸ”§ Validate and Enhance Sources
      run: |
        # sources.json Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ ÙÙ‚Ø· Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ù†ÛŒÙ…
        if [ -f "sources.json" ]; then
          echo "âœ… Found existing sources.json"
          python -c "import json; json.load(open('sources.json'))" || {
            echo "âŒ Invalid sources.json format!"
            exit 1
          }
        else
          echo "âŒ sources.json not found!"
          exit 1
        fi
        
        echo "âœ… sources.json validated successfully"
      timeout-minutes: 2

    - name: ğŸ”§ Execute Enhanced Scraper
      run: |
        echo "ğŸš€ Starting enhanced V2V scraper..."
        
        # Set enhanced environment variables
        export GITHUB_SEARCH_LIMIT=150
        export MAX_CONFIGS_TO_TEST=8000
        export MAX_TEST_WORKERS=80
        
        # Run scraper with comprehensive timeout and error handling
        timeout 2700 python scraper.py 2>&1 | tee scraper.log || {
          exit_code=$?
          echo "Scraper exit code: $exit_code"
          
          if [ $exit_code -eq 124 ]; then
            echo "â° Scraper timeout - creating fallback files..."
            
            # Create comprehensive fallback structure
            cat > all_live_configs.json << 'EOF'
        {
          "xray": {
            "vless": [],
            "vmess": [], 
            "trojan": [],
            "ss": []
          },
          "singbox": {
            "vless": [],
            "vmess": [],
            "trojan": [],
            "ss": [],
            "hysteria2": [],
            "hy2": [],
            "tuic": []
          }
        }
        EOF
            
            cat > clash_subscription.yml << 'EOF'
        proxies: []
        proxy-groups:
          - name: V2V-Auto
            type: select
            proxies: []
        rules:
          - MATCH,DIRECT
        EOF
            
            echo $(date +%s) > cache_version.txt
            echo "âš ï¸ Fallback files created due to timeout"
          else
            echo "âŒ Scraper failed with exit code: $exit_code"
            cat scraper.log | tail -50
            exit 1
          fi
        }
        
        # Validate output files
        for file in "all_live_configs.json" "clash_subscription.yml" "cache_version.txt"; do
          if [ ! -f "$file" ]; then
            echo "âŒ Missing output file: $file"
            exit 1
          fi
          echo "âœ… Found $file ($(wc -c < "$file") bytes)"
        done
        
        # Validate JSON structure
        python3 -c "
        import json
        try:
            data = json.load(open('all_live_configs.json'))
            if not isinstance(data.get('xray'), dict) or not isinstance(data.get('singbox'), dict):
                raise ValueError('Invalid structure')
            print('âœ… JSON structure validated')
        except Exception as e:
            print(f'âŒ JSON validation failed: {e}')
            exit(1)
        " || exit 1
        
        echo "âœ… Enhanced scraper completed successfully"
      env:
        GH_PAT: ${{ secrets.GH_PAT }}
        GITHUB_SEARCH_LIMIT: 150
      timeout-minutes: 47

    - name: ğŸ“Š Calculate Statistics
      id: stats
      run: |
        xray_count=$(python3 -c "
        import json
        try:
            data = json.load(open('all_live_configs.json'))
            count = sum(len(v) for v in data.get('xray', {}).values())
            print(count)
        except:
            print('0')
        " 2>/dev/null)
        
        singbox_count=$(python3 -c "
        import json
        try:
            data = json.load(open('all_live_configs.json'))
            count = sum(len(v) for v in data.get('singbox', {}).values())
            print(count)
        except:
            print('0')
        " 2>/dev/null)
        
        echo "xray_count=$xray_count" >> $GITHUB_OUTPUT
        echo "singbox_count=$singbox_count" >> $GITHUB_OUTPUT
        
        echo "ğŸ“Š Statistics: Xray=$xray_count, Sing-box=$singbox_count"
      timeout-minutes: 2

    - name: ğŸ” Check for Changes
      id: check_changes
      run: |
        git add all_live_configs.json clash_subscription.yml cache_version.txt
        
        if git diff --cached --exit-code > /dev/null 2>&1; then
          echo "configs_updated=false" >> $GITHUB_OUTPUT
          echo "â„¹ï¸ No changes detected"
        else
          echo "configs_updated=true" >> $GITHUB_OUTPUT
          echo "âœ… Changes detected"
        fi
      timeout-minutes: 2

    - name: ğŸ”§ Configure Git
      if: steps.check_changes.outputs.configs_updated == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git config --local core.autocrlf false
        git config --local core.filemode false
      timeout-minutes: 1

    - name: ğŸ’¾ Commit and Push Changes
      if: steps.check_changes.outputs.configs_updated == 'true'
      run: |
        # Create detailed commit message
        commit_msg="ğŸ¤– Enhanced V2V Update: Xray(${{ steps.stats.outputs.xray_count }}) + Sing-box(${{ steps.stats.outputs.singbox_count }}) configs [$(date -u '+%Y-%m-%d %H:%M UTC')]"
        
        git add all_live_configs.json clash_subscription.yml cache_version.txt
        git commit -m "$commit_msg"
        
        # Push with retry mechanism
        for i in {1..3}; do
          if git push origin HEAD:${GITHUB_REF#refs/heads/}; then
            echo "âœ… Changes pushed successfully (attempt $i)"
            break
          else
            echo "âš ï¸ Push failed, retrying in 10s... (attempt $i/3)"
            sleep 10
            git pull --rebase origin ${GITHUB_REF#refs/heads/} || true
          fi
          
          if [ $i -eq 3 ]; then
            echo "âŒ Failed to push after 3 attempts"
            exit 1
          fi
        done
        
        echo "âœ… Repository updated successfully"
      timeout-minutes: 5

  deploy_to_mirrors:
    needs: enhanced_scraping
    runs-on: ubuntu-latest
    if: always() && needs.enhanced_scraping.outputs.configs_updated == 'true'
    timeout-minutes: 20
    
    strategy:
      matrix:
        include:
          - name: "Vercel"
            id: "vercel"
          - name: "Arvan Cloud" 
            id: "arvan"
      fail-fast: false
    
    steps:
    - name: ğŸš€ Checkout Latest Changes
      uses: actions/checkout@v4
      with:
        ref: ${{ github.ref }}
        fetch-depth: 1
      timeout-minutes: 3

    - name: ğŸ” Validate Files Pre-Deploy
      run: |
        echo "ğŸ” Validating files for ${{ matrix.name }} deployment..."
        
        required_files=("all_live_configs.json" "clash_subscription.yml" "cache_version.txt")
        
        for file in "${required_files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "âŒ Missing file: $file - creating placeholder"
            case $file in
              "all_live_configs.json")
                echo '{"xray": {"vless": [], "vmess": [], "trojan": [], "ss": []}, "singbox": {"vless": [], "vmess": [], "trojan": [], "ss": [], "hy2": [], "tuic": []}}' > "$file"
                ;;
              "clash_subscription.yml")
                echo 'proxies: []\nproxy-groups: []\nrules: ["MATCH,DIRECT"]' > "$file"
                ;;
              "cache_version.txt")
                echo $(date +%s) > "$file"
                ;;
            esac
          else
            file_size=$(wc -c < "$file")
            echo "âœ… $file: ${file_size} bytes"
            
            if [ "$file" = "all_live_configs.json" ] && [ "$file_size" -lt 50 ]; then
              echo "âš ï¸ JSON file suspiciously small"
            fi
          fi
        done
        
        # Validate JSON one more time
        python3 -c "import json; json.load(open('all_live_configs.json'))" || {
          echo "âŒ Invalid JSON detected - creating valid structure"
          echo '{"xray": {}, "singbox": {}}' > all_live_configs.json
        }
        
        echo "âœ… All files validated for ${{ matrix.name }}"
      timeout-minutes: 2

    - name: ğŸš€ Deploy to Vercel
      if: matrix.id == 'vercel'
      id: vercel_deploy
      uses: amondnet/vercel-action@v25
      with:
        vercel-token: ${{ secrets.VERCEL_TOKEN }}
        vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
        vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
        vercel-args: '--prod --force'
        github-comment: false
        github-deployment: false
      continue-on-error: true
      timeout-minutes: 10

    # Deploy to Arvan Cloud S3  
    - name: ğŸš€ Deploy to Arvan Cloud S3
      if: matrix.id == 'arvan' && secrets.ARVAN_BUCKET_NAME != ''
      id: arvan_deploy
      uses: jakejarvis/s3-sync-action@master
      with:
        args: --acl public-read --delete --exclude ".git/*" --exclude ".github/*" --exclude "*.py" --exclude "README.md" --exclude "scraper.log" --exclude "*.md"
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_SECRET_ACCESS_KEY }}
        AWS_S3_ENDPOINT: 'https://s3.ir-thr-at1.arvanstorage.ir'
        AWS_S3_BUCKET: ${{ secrets.ARVAN_BUCKET_NAME }}
        SOURCE_DIR: '.'
      continue-on-error: true
      timeout-minutes: 8

    # Handle missing Arvan bucket name
    - name: âš ï¸ Arvan Bucket Missing
      if: matrix.id == 'arvan' && secrets.ARVAN_BUCKET_NAME == ''
      run: |
        echo "WARNING: ARVAN_BUCKET_NAME secret is not set!"
        echo "Please add the following secret to your repository:"
        echo "Name: ARVAN_BUCKET_NAME"
        echo "Value: v2v-data (or your bucket name)"
        echo "::warning::Arvan deployment skipped - missing ARVAN_BUCKET_NAME secret"
        echo "::set-output name=outcome::skipped"
      id: arvan_deploy

    - name: ğŸ“Š Deployment Status
      run: |
        if [ "${{ matrix.id }}" = "vercel" ]; then
          if [ "${{ steps.vercel_deploy.outcome }}" = "success" ]; then
            echo "âœ… Vercel deployment successful"
            echo "ğŸŒ URL: ${{ steps.vercel_deploy.outputs.preview-url }}"
          else
            echo "âŒ Vercel deployment failed"
          fi
        elif [ "${{ matrix.id }}" = "arvan" ]; then
          if [ "${{ steps.arvan_deploy.outcome }}" = "success" ]; then
            echo "âœ… Arvan Cloud deployment successful"
          else
            echo "âŒ Arvan Cloud deployment failed"
          fi
        fi
      timeout-minutes: 1

  github_pages_deploy:
    needs: [enhanced_scraping, deploy_to_mirrors]
    runs-on: ubuntu-latest
    if: always() && needs.enhanced_scraping.outputs.configs_updated == 'true'
    timeout-minutes: 10
    
    permissions:
      contents: read
      pages: write
      id-token: write
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: ğŸš€ Checkout Latest Changes
      uses: actions/checkout@v4
      with:
        ref: ${{ github.ref }}
        fetch-depth: 1

    # Ø­Ø°Ù Ø¨Ø®Ø´ Ø§ÛŒØ¬Ø§Ø¯ index.html Ø¬Ø¯ÛŒØ¯ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
    - name: âœ… Verify Existing Files
      run: |
        echo "ğŸ” Verifying existing project files..."
        
        if [ -f "index.html" ]; then
          echo "âœ… Found existing index.html ($(wc -c < index.html) bytes)"
        else
          echo "âŒ index.html not found!"
          exit 1
        fi
        
        if [ -f "index.js" ]; then
          echo "âœ… Found existing index.js ($(wc -c < index.js) bytes)"
        else
          echo "âŒ index.js not found!"
          exit 1
        fi
        
        # Verify config files exist
        for file in "all_live_configs.json" "clash_subscription.yml" "cache_version.txt"; do
          if [ -f "$file" ]; then
            echo "âœ… Found $file ($(wc -c < "$file") bytes)"
          else
            echo "âš ï¸ Warning: $file not found"
          fi
        done
        
        echo "âœ… File verification completed - using existing user files"
      timeout-minutes: 1

    - name: ğŸ› ï¸ Setup Pages
      uses: actions/configure-pages@v4

    - name: ğŸ“¤ Upload to Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: '.'

    - name: ğŸš€ Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
      timeout-minutes: 5

  final_status_report:
    needs: [enhanced_scraping, deploy_to_mirrors, github_pages_deploy]
    runs-on: ubuntu-latest
    if: always()
    timeout-minutes: 5
    
    steps:
    - name: ğŸ“Š Generate Comprehensive Status Report
      run: |
        echo "=================================================="
        echo "ğŸš€ ENHANCED V2V DEPLOYMENT STATUS REPORT"
        echo "=================================================="
        echo "â° Generated at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        echo ""
        
        # Job statuses
        scraper_status="${{ needs.enhanced_scraping.result }}"
        mirrors_status="${{ needs.deploy_to_mirrors.result }}"
        pages_status="${{ needs.github_pages_deploy.result }}"
        
        echo "ğŸ“‹ Job Results:"
        echo "  ğŸ”§ Enhanced Scraper: $scraper_status"
        echo "  ğŸŒ Mirror Deployment: $mirrors_status"
        echo "  ğŸ“„ GitHub Pages: $pages_status"
        echo ""
        
        # Configuration statistics
        if [ "${{ needs.enhanced_scraping.outputs.configs_updated }}" = "true" ]; then
          xray_count="${{ needs.enhanced_scraping.outputs.xray_count }}"
          singbox_count="${{ needs.enhanced_scraping.outputs.singbox_count }}"
          total_count=$((xray_count + singbox_count))
          
          echo "ğŸ“Š Configuration Statistics:"
          echo "  ğŸ¯ Xray Configs: $xray_count"
          echo "  ğŸ“¦ Sing-box Configs: $singbox_count"
          echo "  ğŸ“ˆ Total Configs: $total_count"
          echo "  âœ… Configs Updated: Yes"
        else
          echo "ğŸ“Š Configuration Statistics:"
          echo "  â„¹ï¸ No configuration changes detected"
        fi
        echo ""
        
        # Mirror status summary
        echo "ğŸŒ Deployment Status Summary:"
        echo "  ğŸ“„ GitHub Pages: https://smbcryp.github.io/V2V/"
        
        if [ "$mirrors_status" = "success" ]; then
          echo "  âœ… Mirror Deployments: Successful"
        elif [ "$mirrors_status" = "failure" ]; then
          echo "  âŒ Mirror Deployments: Some Failed"
        else
          echo "  âš ï¸ Mirror Deployments: Skipped/Partial"
        fi
        echo ""
        
        # Overall assessment
        if [ "$scraper_status" = "success" ] && [ "$pages_status" = "success" ]; then
          echo "ğŸ‰ OVERALL STATUS: SUCCESS"
          echo "âœ… Core functionality operational"
          echo "ğŸ”„ Service continuity maintained"
        elif [ "$scraper_status" = "success" ]; then
          echo "âš ï¸ OVERALL STATUS: PARTIAL SUCCESS"
          echo "âœ… Scraping successful, deployment issues detected"
          echo "ğŸ”§ Manual intervention may be required"
        else
          echo "âŒ OVERALL STATUS: FAILURE"
          echo "ğŸš¨ Core scraping failed"
          echo "ğŸ”§ Investigation required"
        fi
        
        echo ""
        echo "ğŸ“‹ Quick Access URLs:"
        echo "  ğŸ“„ Main Config: https://smbcryp.github.io/V2V/all_live_configs.json"
        echo "  âš”ï¸ Clash Config: https://smbcryp.github.io/V2V/clash_subscription.yml"
        echo "  ğŸ•’ Cache Version: https://smbcryp.github.io/V2V/cache_version.txt"
        echo ""
        echo "=================================================="
        echo "ğŸ”„ Next scheduled run: $(date -u -d '+3 hours' '+%Y-%m-%d %H:%M UTC')"
        echo "=================================================="
      timeout-minutes: 2

Ø§Ù„Ø§Ù† Ø§ÛŒÙ† Ø¯Ø±Ø³ØªÙ‡ØŸØŸØŸ
Ù‡Ù…Ø±Ùˆ Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø±ÛŒØ´Ù‡ Ø¨Ø®ÙˆÙ†Ù‡
Ù…Ø§ output Ù†Ø¯Ø§Ø±ÛŒÙ… Ø¯ÛŒÚ¯Ù‡