name: 'V2V Enhanced Publisher - Complete Protocol Coverage'

on:
  schedule:
    - cron: '0 */3 * * *'  # Every 3 hours for optimal freshness (UTC)
  workflow_dispatch:
  push:
    branches: [ main, master ]
    paths: 
      - 'scraper.py'
      - 'sources.json'
      - '.github/workflows/**'

env:
  WORKFLOW_TIMEOUT_MINUTES: 58
  PYTHON_VERSION: '3.11'

permissions:
  contents: write 
  pages: write    
  id-token: write 
  
jobs:
  enhanced_scraping:
    runs-on: ubuntu-latest
    environment: Production
    timeout-minutes: 50
    
    outputs:
      configs_updated: ${{ steps.check_changes.outputs.configs_updated }}
      xray_count: ${{ steps.stats.outputs.xray_count }}
      singbox_count: ${{ steps.stats.outputs.singbox_count }}
    
    steps:
      - name: üöÄ Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
        timeout-minutes: 3

      - name: üêç Setup Enhanced Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
        timeout-minutes: 5

      - name: üì¶ Install Enhanced Dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install requests PyGithub PyYAML urllib3 certifi
          pip install --upgrade requests urllib3
          echo "‚úÖ Dependencies installed successfully"
        timeout-minutes: 5

      - name: üîß Validate and Enhance Sources
        run: |
          if [ -f "sources.json" ]; then
            echo "‚úÖ Found existing sources.json"
            python -c "import json; json.load(open('sources.json'))" || {
              echo "‚ùå Invalid sources.json format!"
              exit 1
            }
          else
            echo "‚ùå sources.json not found!"
            exit 1
          fi

          echo "‚úÖ sources.json validated successfully"
        timeout-minutes: 2

      - name: üîß Execute Enhanced Scraper
        timeout-minutes: 47 
        run: |
          echo "üöÄ Starting enhanced V2V scraper..."
          
          # Run scraper with comprehensive timeout and error handling
          timeout 2700 python scraper.py 2>&1 | tee scraper.log || {
            exit_code=$?
            echo "Scraper exit code: $exit_code"
            
            if [ $exit_code -eq 124 ]; then
              echo "‚è∞ Scraper timeout - creating fallback files..."
              
              # Create comprehensive fallback structure
              cat > all_live_configs.json <<'EOF'
{
  "xray": {
    "vless": [],
    "vmess": [], 
    "trojan": [],
    "ss": []
  },
  "singbox": {
    "vless": [],
    "vmess": [],
    "trojan": [],
    "ss": [],
    "hysteria2": [],
    "hy2": [],
    "tuic": []
  }
}
EOF
              cat > clash_subscription.yml <<'EOF'
proxies: []
proxy-groups:
  - name: V2V-Auto
    type: select
    proxies: []
rules:
  - MATCH,DIRECT
EOF
              date +%s > cache_version.txt
              echo "‚ö†Ô∏è Fallback files created due to timeout"
            else
              echo "‚ùå Scraper failed with exit code: $exit_code"
              tail -50 scraper.log
              exit 1
            fi
          }
          
          # Validate output files
          for file in "all_live_configs.json" "clash_subscription.yml" "cache_version.txt"; do
            if [ ! -f "$file" ]; then
              echo "‚ùå Missing output file: $file"
              exit 1
            fi
            echo "‚úÖ Found $file ($(wc -c < "$file") bytes)"
          done
          
          # Validate JSON structure
          python3 -c "
import json
try:
  data = json.load(open('all_live_configs.json'))
  if not isinstance(data.get('xray'), dict) or not isinstance(data.get('singbox'), dict):
    raise ValueError('Invalid structure')
  print('‚úÖ JSON structure validated')
except Exception as e:
  print(f'‚ùå JSON validation failed: {e}')
  exit(1)
" || exit 1
          
          echo "‚úÖ Enhanced scraper completed successfully"
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          GITHUB_SEARCH_LIMIT: 150
          MAX_CONFIGS_TO_TEST: 8000
          MAX_TEST_WORKERS: 80
          V2V_LOG_LEVEL: INFO 

      - name: üìä Calculate Statistics
        id: stats
        run: |
          xray_count=$(python3 -c "
import json
try:
  data = json.load(open('all_live_configs.json'))
  count = sum(len(v) for v in data.get('xray', {}).values())
  print(count)
except:
  print('0')
" 2>/dev/null)
          singbox_count=$(python3 -c "
import json
try:
  data = json.load(open('all_live_configs.json'))
  count = sum(len(v) for v in data.get('singbox', {}).values())
  print(count)
except:
  print('0')
" 2>/dev/null)
          echo "xray_count=$xray_count" >> $GITHUB_OUTPUT
          echo "singbox_count=$singbox_count" >> $GITHUB_OUTPUT
          echo "üìä Statistics: Xray=$xray_count, Sing-box=$singbox_count"
        timeout-minutes: 2

      - name: üîç Check for Changes
        id: check_changes
        run: |
          git add all_live_configs.json clash_subscription.yml cache_version.txt
          if git diff --cached --exit-code > /dev/null 2>&1; then
            echo "configs_updated=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è No changes detected"
          else
            echo "configs_updated=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Changes detected"
          fi
        timeout-minutes: 2

      - name: üîß Configure Git
        if: steps.check_changes.outputs.configs_updated == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git config --local core.autocrlf false
          git config --local core.filemode false
        timeout-minutes: 1

      - name: üíæ Commit and Push Changes
        if: steps.check_changes.outputs.configs_updated == 'true'
        run: |
          commit_msg="ü§ñ Enhanced V2V Update: Xray(${{ steps.stats.outputs.xray_count }}) + Sing-box(${{ steps.stats.outputs.singbox_count }}) configs [$(date -u '+%Y-%m-%d %H:%M UTC')]"
          git add all_live_configs.json clash_subscription.yml cache_version.txt
          git commit -m "$commit_msg"
          for i in {1..3}; do
            if git push origin HEAD:${GITHUB_REF#refs/heads/}; then
              echo "‚úÖ Changes pushed successfully (attempt $i)"
              break
            else
              echo "‚ö†Ô∏è Push failed, retrying in 10s... (attempt $i/3)"
              sleep 10
              git pull origin ${GITHUB_REF#refs/heads/} --rebase || true 
            fi
            if [ $i -eq 3 ]; then
              echo "‚ùå Failed to push after 3 attempts"
              exit 1
            fi
          done
          echo "‚úÖ Repository updated successfully"
        timeout-minutes: 5

  deploy_to_mirrors:
    needs: enhanced_scraping
    runs-on: ubuntu-latest
    if: success() && needs.enhanced_scraping.outputs.configs_updated == 'true'
    timeout-minutes: 20
    
    strategy:
      matrix:
        include:
          - name: "Vercel"
            id: "vercel"
          - name: "Arvan Cloud" 
            id: "arvan"
      fail-fast: false
    
    steps:
      - name: üöÄ Checkout Latest Changes
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
          fetch-depth: 1
        timeout-minutes: 3

      - name: üîç Validate Files Pre-Deploy
        run: |
          echo "üîç Validating files for ${{ matrix.name }} deployment..."
          required_files=("all_live_configs.json" "clash_subscription.yml" "cache_version.txt")
          for file in "${required_files[@]}"; do
            if [ ! -f "$file" ]; then
              echo "‚ùå Missing file: $file - creating placeholder"
              case $file in
                "all_live_configs.json")
                  echo '{"xray": {"vless": [], "vmess": [], "trojan": [], "ss": []}, "singbox": {"vless": [], "vmess": [], "trojan": [], "ss": [], "hy2": [], "tuic": []}}' > "$file"
                  ;;
                "clash_subscription.yml")
                  echo -e 'proxies: []\nproxy-groups: []\nrules: ["MATCH,DIRECT"]' > "$file"
                  ;;
                "cache_version.txt")
                  date +%s > "$file"
                  ;;
              esac
            else
              file_size=$(wc -c < "$file")
              echo "‚úÖ $file: ${file_size} bytes"
              if [ "$file" = "all_live_configs.json" ] && [ "$file_size" -lt 50 ]; then
                echo "‚ö†Ô∏è JSON file suspiciously small"
              fi
            fi
          done
          python3 -c "import json; json.load(open('all_live_configs.json'))" || {
            echo "‚ùå Invalid JSON detected - creating valid structure"
            echo '{"xray": {}, "singbox": {}}' > all_live_configs.json
          }
          echo "‚úÖ All files validated for ${{ matrix.name }}"
        timeout-minutes: 2

      - name: üöÄ Deploy to Vercel
        if: matrix.id == 'vercel'
        id: vercel_deploy
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prod --force'
          github-comment: false
          github-deployment: false
        continue-on-error: true
        timeout-minutes: 10

      - name: üöÄ Deploy to Arvan Cloud S3
        if: matrix.id == 'arvan' && secrets.ARVAN_BUCKET_NAME != ''
        id: arvan_deploy
        uses: jakejarvis/s3-sync-action@master
        with:
          args: --acl public-read --delete --exclude ".git/*" --exclude ".github/*" --exclude "*.py" --exclude "README.md" --exclude "scraper.log" --exclude "*.md"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARVAN_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARVAN_SECRET_ACCESS_KEY }}
          AWS_S3_ENDPOINT: 'https://s3.ir-thr-at1.arvanstorage.ir'
          AWS_S3_BUCKET: ${{ secrets.ARVAN_BUCKET_NAME }}
          SOURCE_DIR: '.'
        continue-on-error: true
        timeout-minutes: 8

      - name: ‚ö†Ô∏è Arvan Bucket Missing
        if: matrix.id == 'arvan' && secrets.ARVAN_BUCKET_NAME == ''
        run: |
          echo "WARNING: ARVAN_BUCKET_NAME secret is not set!"
          echo "::warning::Arvan deployment skipped - missing ARVAN_BUCKET_NAME secret"
        id: arvan_deploy

      - name: üìä Deployment Status
        run: |
          if [ "${{ matrix.id }}" = "vercel" ]; then
            if [ "${{ steps.vercel_deploy.outcome }}" = "success" ]; then
              echo "‚úÖ Vercel deployment successful"
              echo "üåê URL: ${{ steps.vercel_deploy.outputs.preview-url }}"
            else
              echo "‚ùå Vercel deployment failed"
            fi
          elif [ "${{ matrix.id }}" = "arvan" ]; then
            if [ "${{ steps.arvan_deploy.outcome }}" = "success" ]; then
              echo "‚úÖ Arvan Cloud deployment successful"
            else
              echo "‚ùå Arvan Cloud deployment failed"
            fi
          fi
        timeout-minutes: 1

  github_pages_deploy:
    needs: [enhanced_scraping, deploy_to_mirrors]
    runs-on: ubuntu-latest
    if: success() && needs.enhanced_scraping.outputs.configs_updated == 'true'
    timeout-minutes: 10
    
    permissions:
      contents: read
      pages: write
      id-token: write
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: üöÄ Checkout Latest Changes
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
          fetch-depth: 1

      - name: ‚úÖ Verify Existing Files
        run: |
          echo "üîç Verifying existing project files..."
          for file in "index.html" "index.js"; do
            if [ -f "$file" ]; then
              echo "‚úÖ Found existing $file ($(wc -c < "$file") bytes)"
            else
              echo "‚ùå $file not found! Cannot deploy Pages."
              exit 1
            fi
          done
          for file in "all_live_configs.json" "clash_subscription.yml" "cache_version.txt"; do
            if [ -f "$file" ]; then
              echo "‚úÖ Found $file ($(wc -c < "$file") bytes)"
            else
              echo "‚ö†Ô∏è Warning: $file not found - Deployment will be based on what's available."
            fi
          done
          echo "‚úÖ File verification completed - using existing user files"
        timeout-minutes: 1

      - name: üõ†Ô∏è Setup Pages
        uses: actions/configure-pages@v4

      - name: üì§ Upload to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

      - name: üöÄ Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        timeout-minutes: 5

  final_status_report:
    needs: [enhanced_scraping, deploy_to_mirrors, github_pages_deploy]
    runs-on: ubuntu-latest
    if: always() 
    timeout-minutes: 5
    
    steps:
      - name: üìä Generate Comprehensive Status Report
        run: |
          echo "=================================================="
          echo "üöÄ ENHANCED V2V DEPLOYMENT STATUS REPORT"
          echo "=================================================="
          echo "‚è∞ Generated at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          scraper_status="${{ needs.enhanced_scraping.result }}"
          mirrors_status="${{ needs.deploy_to_mirrors.result }}"
          pages_status="${{ needs.github_pages_deploy.result }}"
          echo "üìã Job Results:"
          echo "  üîß Enhanced Scraper: $scraper_status"
          echo "  üåê Mirror Deployment: $mirrors_status"
          echo "  üìÑ GitHub Pages: $pages_status"
          echo ""
          if [ "$scraper_status" = "success" ] && [ "${{ needs.enhanced_scraping.outputs.configs_updated }}" = "true" ]; then
            xray_count="${{ needs.enhanced_scraping.outputs.xray_count }}"
            singbox_count="${{ needs.enhanced_scraping.outputs.singbox_count }}"
            total_count=$((xray_count + singbox_count))
            echo "üìä Configuration Statistics:"
            echo "  üéØ Xray Configs: $xray_count"
            echo "  üì¶ Sing-box Configs: $singbox_count"
            echo "  üìà Total Configs: $total_count"
            echo "  ‚úÖ Configs Updated: Yes"
          elif [ "$scraper_status" = "success" ]; then
            echo "üìä Configuration Statistics:"
            echo "  ‚ÑπÔ∏è No new configuration changes detected"
          else
            echo "üìä Configuration Statistics:"
            echo "  ‚ùå Scraping failed - no data available"
          fi
          echo ""
          echo "üåê Deployment Status Summary:"
          echo "  üìÑ GitHub Pages: https://smbcryp.github.io/V2V/"
          if [ "$mirrors_status" = "success" ]; then
            echo "  ‚úÖ Mirror Deployments: Successful"
          elif [ "$mirrors_status" = "failure" ]; then
            echo "  ‚ùå Mirror Deployments: Failed (check logs)"
          elif [ "$mirrors_status" = "skipped" ]; then
            echo "  ‚ÑπÔ∏è Mirror Deployments: Skipped (no changes or Scraper failed)"
          else
            echo "  ‚ö†Ô∏è Mirror Deployments: Status Unknown/Pending"
          fi
          echo ""
          if [ "$scraper_status" = "success" ] && [ "$pages_status" = "success" ]; then
            echo "üéâ OVERALL STATUS: SUCCESS"
            echo "‚úÖ Core functionality and main deployment operational"
          elif [ "$scraper_status" = "success" ]; then
            echo "‚ö†Ô∏è OVERALL STATUS: PARTIAL SUCCESS"
            echo "‚úÖ Scraping successful, deployment issues detected (Mirrors/Pages)"
          else
            echo "‚ùå OVERALL STATUS: FAILURE"
            echo "üö® Core scraping failed - Investigation required"
          fi
          echo ""
          echo "üìã Quick Access URLs:"
          echo "  üìÑ Main Config: https://smbcryp.github.io/V2V/all_live_configs.json"
          echo "  ‚öîÔ∏è Clash Config: https://smbcryp.github.io/V2V/clash_subscription.yml"
          echo "  üïí Cache Version: https://smbcryp.github.io/V2V/cache_version.txt"
          echo ""
          echo "=================================================="
          echo "üîÑ Next scheduled run: $(date -u -d '+3 hours' '+%Y-%m-%d %H:%M UTC')"
          echo "=================================================="
        timeout-minutes: 2
