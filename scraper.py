# -*- coding: utf-8 -*-

import requests
import base64
import os
import json
import re
import time
import yaml
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qsl, unquote
from github import Github, Auth

# =================================================================================
# === CONFIGURATION (ØªÙ†Ø¸ÛŒÙ…Ø§Øª) ===
# =================================================================================

# --- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ
SOURCES_FILE = "sources.json"
OUTPUT_JSON_FILE = "all_live_configs.json"
OUTPUT_CLASH_FILE = "clash_subscription.yaml"

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
# Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬
VALID_PREFIXES = ('vless://', 'vmess://', 'trojan://', 'ss://', 'hysteria2://', 'hy2://', 'tuic://')
# Ù‡Ø¯Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ Ø¬Ù‡Øª Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù†
HEADERS = {'User-Agent': 'V2V-Scraper/v4.0-Final'}

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨
# ØªÙˆÚ©Ù† Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾ÙˆÛŒØ§ Ø§Ø² GitHub Actions Secrets Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
GITHUB_PAT = os.environ.get('GH_PAT')
# Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù
GITHUB_SEARCH_LIMIT = 50
# ÙÙ‚Ø· Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± X Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ø¨Ø±Ø±Ø³ÛŒ Ø´ÙˆÙ†Ø¯
GITHUB_FRESHNESS_HOURS = 48
# Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ
GITHUB_SEARCH_QUERIES = ['v2ray subscription', 'vless subscription', 'proxy subscription']

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ³Øª Ø³Ø±Ø¹Øª Ùˆ Ú©ÛŒÙÛŒØªâ€ŒØ³Ù†Ø¬ÛŒ
# API ØªØ³ØªÛŒ Ú©Ù‡ Ø³Ø§Ø®ØªÙ‡â€ŒØ§ÛŒØ¯ (Ø¯Ø± ÙˆØ±Ø³Ù„ ÛŒØ§ Ú©Ù„ÙˆØ¯ÙÙ„Ø±)
SPEED_TEST_API_ENDPOINT = 'https://v2-v.vercel.app/api/proxy'
# Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ú©Ø±Ø¯Ù† (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ÙØ´Ø§Ø± Ø¨Ø± API)
MAX_CONFIGS_TO_TEST = 2000
# ØªØ¹Ø¯Ø§Ø¯ ØªØ³Øª Ù‡Ù…Ø²Ù…Ø§Ù† Ø¯Ø± Ù‡Ø± Batch
SPEED_TEST_BATCH_SIZE = 20
# Ø­Ø¯Ø§Ú©Ø«Ø± Ù¾ÛŒÙ†Ú¯ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ (Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡)
MAX_PING_THRESHOLD = 1200
# ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù‡Ø³ØªÙ‡
TARGET_CONFIGS_PER_CORE = 400
# Ù…Ù‡Ù„Øª Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ³Øª (Ø«Ø§Ù†ÛŒÙ‡)
REQUEST_TIMEOUT = 10

if GITHUB_PAT:
    HEADERS['Authorization'] = f'token {GITHUB_PAT}'

# =================================================================================
# === CORE FUNCTIONS (ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ) ===
# =================================================================================

def get_static_sources() -> list:
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ù†Ø§Ø¨Ø¹ Ø«Ø§Ø¨Øª Ø§Ø² ÙØ§ÛŒÙ„ sources.json"""
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f).get("static", [])
    except Exception:
        return []

def discover_dynamic_sources() -> list:
    """Ú©Ø´Ù Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ§Ø²Ù‡ Ø§Ø² GitHub"""
    if not GITHUB_PAT:
        print("âš ï¸ ØªÙˆÚ©Ù† Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ (GH_PAT) ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾ÙˆÛŒØ§ ØµØ±Ù Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return []
    
    print("ğŸ” Ú©Ø´Ù Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ§Ø²Ù‡ Ø§Ø² GitHub...")
    auth = Auth.Token(GITHUB_PAT)
    g = Github(auth=auth, timeout=20)
    
    freshness_threshold = datetime.now(timezone.utc) - timedelta(hours=GITHUB_FRESHNESS_HOURS)
    dynamic_sources = set()

    for query in GITHUB_SEARCH_QUERIES:
        try:
            repos = g.search_repositories(query=f'{query} language:text', sort='updated', order='desc')
            
            for repo in repos:
                if repo.updated_at < freshness_threshold:
                    break 
                
                if len(dynamic_sources) >= GITHUB_SEARCH_LIMIT:
                    break

                try:
                    contents = repo.get_contents("")
                    for content_file in contents:
                        if content_file.type == 'file' and content_file.name.lower().endswith(('.txt', '.md', '.yaml', '.yml')):
                            dynamic_sources.add(content_file.download_url)
                except Exception:
                    continue
            
            if len(dynamic_sources) >= GITHUB_SEARCH_LIMIT:
                break
        except Exception as e:
            print(f"   - Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨: {e}")
            break # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø§Ø² Ø§Ø¯Ø§Ù…Ù‡ Ø¬Ø³ØªØ¬Ùˆ ØµØ±Ù Ù†Ø¸Ø± Ú©Ù†
    
    print(f"âœ… {len(dynamic_sources)} Ù…Ù†Ø¨Ø¹ Ù¾ÙˆÛŒØ§ÛŒ ØªØ§Ø²Ù‡ Ú©Ø´Ù Ø´Ø¯.")
    return list(dynamic_sources)

def fetch_and_parse_url(url: str) -> set:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² ÛŒÚ© URL"""
    try:
        response = requests.get(url, timeout=15, headers=HEADERS)
        response.raise_for_status()
        content = response.text
        
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Base64
        try:
            decoded_content = base64.b64decode(content).decode('utf-8')
            content = decoded_content
        except Exception:
            pass # Ø§Ú¯Ø± Base64 Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² Ù‡Ù…Ø§Ù† Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ø§ Regex
        pattern = r'(' + '|'.join(p for p in VALID_PREFIXES) + r')[^\s\'"<>]+'
        return set(re.findall(pattern, content))

    except requests.RequestException:
        return set()

def test_config_via_api(config_str: str) -> dict:
    """ØªØ³Øª ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ API ÙˆØ±Ø³Ù„"""
    try:
        parsed = urlparse(config_str)
        host = parsed.hostname
        port = parsed.port

        if parsed.scheme == 'vmess':
            decoded = json.loads(base64.b64decode(config_str.replace("vmess://", "")).decode('utf-8'))
            host, port = decoded['add'], int(decoded['port'])
        
        if not port:
            port = {'ss': 8443, 'trojan': 443, 'vless': 443}.get(parsed.scheme, 443)

        response = requests.post(
            SPEED_TEST_API_ENDPOINT,
            json={'host': host, 'port': port},
            headers={'Content-Type': 'application/json'},
            timeout=REQUEST_TIMEOUT
        )
        
        if response.status_code == 200:
            return {'config_str': config_str, 'ping': response.json().get('ping', 9999)}
        return {'config_str': config_str, 'ping': 9999}
    except Exception:
        return {'config_str': config_str, 'ping': 9999}

def validate_and_categorize_configs(configs: set) -> dict:
    """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ù‡ Xray Ùˆ Sing-box"""
    categorized = {'xray': set(), 'singbox': set()}
    for cfg in configs:
        try:
            parsed = urlparse(cfg)
            core = 'xray'
            if parsed.scheme in ('hysteria2', 'hy2', 'tuic'):
                core = 'singbox'
            elif 'reality' in parse_qsl(parsed.query):
                core = 'singbox'
            categorized[core].add(cfg)
        except Exception:
            continue
    return categorized

def generate_clash_subscription(configs: list) -> str:
    """ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ø§Ø´ØªØ±Ø§Ú© Ú©Ù„Ø´ Ø§Ø² Ù„ÛŒØ³Øª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ"""
    proxies = []
    for config_str in configs:
        try:
            protocol = config_str.split("://")[0]
            if protocol not in ('vless', 'vmess', 'trojan', 'ss'): continue
            
            url = urlparse(config_str)
            if 'reality' in url.query.lower(): continue

            name = unquote(url.fragment) if url.fragment else url.hostname
            proxy = {'name': name, 'type': protocol, 'server': url.hostname, 'port': int(url.port)}
            
            if protocol == 'vless':
                params = dict(parse_qsl(url.query))
                proxy.update({'uuid': url.username, 'tls': params.get('security') == 'tls', 'network': params.get('type', 'tcp'), 'servername': params.get('sni', url.hostname), 'skip-cert-verify': True})
                if proxy.get('network') == 'ws':
                    proxy['ws-opts'] = {'path': params.get('path', '/'), 'headers': {'Host': params.get('host', url.hostname)}}
            elif protocol == 'vmess':
                decoded = json.loads(base64.b64decode(config_str.replace("vmess://", "")).decode('utf-8'))
                proxy.update({'uuid': decoded.get('id'), 'alterId': decoded.get('aid'), 'cipher': decoded.get('scy', 'auto'), 'tls': decoded.get('tls') == 'tls', 'network': decoded.get('net', 'tcp'), 'servername': decoded.get('sni', decoded['add']), 'skip-cert-verify': True})
                proxy.update({'server': decoded.get('add'), 'port': int(decoded.get('port'))})
            elif protocol == 'trojan':
                params = dict(parse_qsl(url.query))
                proxy.update({'password': url.username, 'sni': params.get('sni', url.hostname), 'skip-cert-verify': True})
            elif protocol == 'ss':
                cred = base64.b64decode(unquote(url.username)).decode().split(':')
                proxy.update({'cipher': cred[0], 'password': cred[1]})
            
            proxies.append(proxy)
        except Exception:
            continue
            
    clash_config = {'proxies': proxies}
    return yaml.dump(clash_config, allow_unicode=True, sort_keys=False)

# =================================================================================
# === MAIN EXECUTION (Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ) ===
# =================================================================================
def main():
    print("ğŸš€ V2V Scraper v4.0 - Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø¯ØºØ§Ù… Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ...")
    start_time = time.time()

    # --- 1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ù†Ø§Ø¨Ø¹ ---
    static_sources = get_static_sources()
    dynamic_sources = discover_dynamic_sources()
    all_sources = list(set(static_sources + dynamic_sources))
    print(f"ğŸ“¡ Ù…Ø¬Ù…ÙˆØ¹ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡: {len(all_sources)} ( {len(static_sources)} Ø«Ø§Ø¨Øª + {len(dynamic_sources)} Ù¾ÙˆÛŒØ§ )")

    # --- 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ ---
    print("\nğŸšš Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§...")
    raw_configs = set()
    with ThreadPoolExecutor(max_workers=30) as executor:
        for result in executor.map(fetch_and_parse_url, all_sources):
            raw_configs.update(result)
    print(f"ğŸ“¦ {len(raw_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")

    if not raw_configs:
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
        return

    # --- 3. Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ---
    print("\nğŸ”¬ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§ÙˆÙ„ÛŒØ¹...")
    categorized_configs = validate_and_categorize_configs(raw_configs)
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Xray Ø¨Ù‡ Sing-box Ø¨Ø±Ø§ÛŒ Ø¬Ø§Ù…Ø¹ÛŒØª
    categorized_configs['singbox'].update(categorized_configs['xray'])
    
    print(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: {len(categorized_configs['xray'])} Ú©Ø§Ù†ÙÛŒÚ¯ Xray | {len(categorized_configs['singbox'])} Ú©Ø§Ù†ÙÛŒÚ¯ Sing-box")

    # --- 4. ØªØ³Øª Ø³Ø±Ø¹Øª Ùˆ Ú©ÛŒÙÛŒØªâ€ŒØ³Ù†Ø¬ÛŒ ---
    final_configs = {'xray': [], 'singbox': []}
    for core_name, configs_to_test in categorized_configs.items():
        if not configs_to_test: continue
        
        # Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ÙØ´Ø§Ø± Ø¨Ø± API
        if len(configs_to_test) > MAX_CONFIGS_TO_TEST:
            print(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ {core_name} ({len(configs_to_test)}) Ø²ÛŒØ§Ø¯ Ø§Ø³Øª. {MAX_CONFIGS_TO_TEST} Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            configs_to_test = list(configs_to_test)[:MAX_CONFIGS_TO_TEST]

        print(f"\nğŸƒâ€â™‚ï¸ Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ø³Ø±Ø¹Øª {len(configs_to_test)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø±Ø§ÛŒ Ù‡Ø³ØªÙ‡ {core_name.upper()}...")
        
        fast_configs = []
        with ThreadPoolExecutor(max_workers=30) as executor:
            future_to_config = {executor.submit(test_config_via_api, cfg): cfg for cfg in configs_to_test}
            for future in as_completed(future_to_config):
                result = future.result()
                if result['ping'] < MAX_PING_THRESHOLD:
                    fast_configs.append(result)

        print(f"âš¡ {len(fast_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø±ÛŒØ¹ (Ø²ÛŒØ± {MAX_PING_THRESHOLD}ms) Ø¨Ø±Ø§ÛŒ {core_name} ÛŒØ§ÙØª Ø´Ø¯.")

        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾ÛŒÙ†Ú¯ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§
        fast_configs.sort(key=lambda x: x['ping'])
        final_configs[core_name] = fast_configs[:TARGET_CONFIGS_PER_CORE]

    # --- 5. ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ ---
    print("\nğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")

    # 5.1: ØªÙˆÙ„ÛŒØ¯ all_live_configs.json (Ø¨Ø§ ÙØ±Ù…Øª Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯)
    output_for_frontend = {
        'xray': [cfg['config_str'] for cfg in final_configs['xray']],
        'singbox': [cfg['config_str'] for cfg in final_configs['singbox']]
    }
    with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_for_frontend, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_JSON_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")

    # 5.2: ØªÙˆÙ„ÛŒØ¯ clash_subscription.yaml
    clash_content = generate_clash_subscription(output_for_frontend['xray'])
    with open(OUTPUT_CLASH_FILE, 'w', encoding='utf-8') as f:
        f.write(clash_content)
    print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_CLASH_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø´ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")

    # --- 6. Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ---
    total_final_configs = len(output_for_frontend['xray']) + len(output_for_frontend['singbox'])
    elapsed_time = time.time() - start_time
    print("\nğŸ‰ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    print("="*30)
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
    print(f"   -  à¦®à§‹à¦Ÿ Xray Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ: {len(output_for_frontend['xray'])}")
    print(f"   - à¦®à§‹à¦Ÿ Sing-box Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ: {len(output_for_frontend['singbox'])}")
    print(f"   - Ù…Ø¬Ù…ÙˆØ¹ Ú©Ù„: {total_final_configs} Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø§Ù„Ù… Ùˆ Ø³Ø±ÛŒØ¹")
    print(f"   - Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {elapsed_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
    print("="*30)

if __name__ == "__main__":
    main()
