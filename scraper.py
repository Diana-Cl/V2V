# -*- coding: utf-8 -*-

import requests
import base64
import os
import json
import re
import time
import yaml
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qsl, unquote, urlencode, quote
from github import Github, Auth, GithubException
from bs4 import BeautifulSoup

# =================================================================================
# === CONFIGURATION (ØªÙ†Ø¸ÛŒÙ…Ø§Øª) ===
# =================================================================================

# --- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ
SOURCES_FILE = "sources.json"
OUTPUT_JSON_FILE = "all_live_configs.json"
OUTPUT_CLASH_FILE = "clash_subscription.yaml"

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
VALID_PREFIXES = ('vless://', 'vmess://', 'trojan://', 'ss://', 'hysteria2://', 'hy2://', 'tuic://')

# --- Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø¶Ø¯ Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ØªØ§Ø²Ù‡
HEADERS = {
    'User-Agent': 'V2V-Scraper/v5.4-MultiFormat',
    'Cache-Control': 'no-cache, no-store, must-revalidate',
    'Pragma': 'no-cache',
    'Expires': '0'
}

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨
GITHUB_PAT = os.environ.get('GH_PAT')
GITHUB_SEARCH_LIMIT = 50
GITHUB_FRESHNESS_HOURS = 120 # (5 Ø±ÙˆØ²)
GITHUB_SEARCH_QUERIES = ['v2ray subscription', 'vless subscription', 'proxy subscription']

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ³Øª Ø³Ø±Ø¹Øª Ùˆ Ú©ÛŒÙÛŒØªâ€ŒØ³Ù†Ø¬ÛŒ
SPEED_TEST_API_ENDPOINT = 'https://v2-v.vercel.app/api/proxy'
MAX_CONFIGS_TO_TEST = 2000
MAX_PING_THRESHOLD = 5000 # (5 Ø«Ø§Ù†ÛŒÙ‡)
TARGET_CONFIGS_PER_CORE = 500
REQUEST_TIMEOUT = 10

if GITHUB_PAT:
    HEADERS['Authorization'] = f'token {GITHUB_PAT}'

# =================================================================================
# === HELPER FUNCTIONS (ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ) ===
# =================================================================================

def _decode_padded_b64(encoded_str: str) -> str:
    """ÛŒÚ© Ø±Ø´ØªÙ‡ Base64 Ø±Ø§ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù† padding Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    padded_str = encoded_str + '=' * (-len(encoded_str) % 4)
    try:
        return base64.b64decode(padded_str).decode('utf-8')
    except Exception:
        return ""

def _encode_b64(text: str) -> str:
    """ÛŒÚ© Ø±Ø´ØªÙ‡ Ø±Ø§ Ø¨Ù‡ Base64 Ø§Ù†Ú©ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    return base64.b64encode(text.encode('utf-8')).decode('utf-8')

# =================================================================================
# === PARSING ENGINE (Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù) ===
# =================================================================================

def parse_structured_json(content: dict) -> set:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ (Ù…Ø§Ù†Ù†Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯ Sing-box) Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§."""
    configs = set()
    if 'outbounds' not in content or not isinstance(content['outbounds'], list):
        return configs
        
    for outbound in content['outbounds']:
        try:
            protocol = outbound.get('protocol') or outbound.get('type')
            if not protocol: continue
            
            config_str = ""
            if protocol == 'vless':
                server, port, uuid = outbound.get('server'), outbound.get('server_port'), outbound.get('uuid')
                if not all([server, port, uuid]): continue
                name = outbound.get('tag', server)
                params = { 'type': outbound.get('transport', {}).get('type', 'tcp') }
                if outbound.get('tls', {}).get('enabled'):
                    tls_settings = outbound['tls']
                    params['security'] = 'tls'
                    params['sni'] = tls_settings.get('server_name', server)
                    if tls_settings.get('reality', {}).get('enabled'):
                        params['security'] = 'reality'
                        params['pbk'] = tls_settings['reality']['public_key']
                        params['sid'] = tls_settings['reality'].get('short_id', '')
                query_string = urlencode({k: v for k, v in params.items() if v})
                config_str = f"vless://{uuid}@{server}:{port}?{query_string}#{quote(name)}"

            elif protocol == 'vmess':
                server, port, uuid = outbound.get('server'), outbound.get('server_port'), outbound.get('uuid')
                if not all([server, port, uuid]): continue
                name = outbound.get('tag', server)
                vmess_data = {
                    "v": "2", "ps": name, "add": server, "port": port, "id": uuid,
                    "aid": outbound.get('alter_id', 0), "net": outbound.get('transport', {}).get('type', 'tcp'),
                    "type": "none", "host": "", "path": "", "tls": "none", "sni": ""
                }
                config_str = f"vmess://{_encode_b64(json.dumps(vmess_data, separators=(',', ':')))}"

            if config_str:
                configs.add(config_str)
        except (KeyError, TypeError):
            continue
    return configs

def parse_structured_yaml(content: dict) -> set:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ YAML (Ù…Ø§Ù†Ù†Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯ Clash) Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ Ù„ÛŒÙ†Ú© Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯."""
    configs = set()
    if 'proxies' not in content or not isinstance(content['proxies'], list):
        return configs

    for proxy in content['proxies']:
        try:
            protocol = proxy.get('type')
            server, port, name = proxy.get('server'), proxy.get('port'), proxy.get('name')
            if not all([protocol, server, port, name]): continue
            
            config_str = ""
            if protocol == 'vless':
                uuid = proxy.get('uuid')
                if not uuid: continue
                params = {'type': proxy.get('network', 'tcp'), 'sni': proxy.get('servername', server)}
                if proxy.get('tls'): params['security'] = 'tls'
                query_string = urlencode({k: v for k, v in params.items() if v})
                config_str = f"vless://{uuid}@{server}:{port}?{query_string}#{quote(name)}"

            elif protocol == 'vmess':
                uuid = proxy.get('uuid')
                if not uuid: continue
                vmess_data = {
                    "v": "2", "ps": name, "add": server, "port": port, "id": uuid,
                    "aid": proxy.get('alterId', 0), "net": proxy.get('network', 'tcp'),
                    "type": "none", "host": proxy.get('ws-opts', {}).get('headers', {}).get('Host', ''),
                    "path": proxy.get('ws-opts', {}).get('path', ''), "tls": "tls" if proxy.get('tls') else "none",
                    "sni": proxy.get('servername', server)
                }
                config_str = f"vmess://{_encode_b64(json.dumps(vmess_data, separators=(',', ':')))}"
            
            elif protocol == 'trojan':
                password = proxy.get('password')
                if not password: continue
                params = {'sni': proxy.get('sni', server)}
                query_string = urlencode({k: v for k, v in params.items() if v})
                config_str = f"trojan://{password}@{server}:{port}?{query_string}#{quote(name)}"

            if config_str:
                configs.add(config_str)
        except (KeyError, TypeError, AttributeError):
            continue
    return configs

def parse_html_content(content: str) -> set:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ HTML."""
    soup = BeautifulSoup(content, 'html.parser')
    text_content = soup.get_text(separator='\n')
    pattern = r'(' + '|'.join(p for p in VALID_PREFIXES) + r')[^\s\'"<>]+'
    return set(re.findall(pattern, text_content))

def fetch_and_parse_url(url: str) -> set:
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² ÛŒÚ© URL Ø¨Ø§ Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯."""
    try:
        response = requests.get(url, timeout=15, headers=HEADERS)
        response.raise_for_status()
        content = response.text

        # --- Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ---
        # 1. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† JSON
        try:
            json_content = json.loads(content)
            parsed_configs = parse_structured_json(json_content)
            if parsed_configs: return parsed_configs
        except json.JSONDecodeError:
            pass # Ø§Ú¯Ø± Ø¬ÛŒØ³ÙˆÙ† Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ Ù…ÛŒâ€ŒØ±ÙˆØ¯

        # 2. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† YAML
        try:
            yaml_content = yaml.safe_load(content)
            if isinstance(yaml_content, dict):
                parsed_configs = parse_structured_yaml(yaml_content)
                if parsed_configs: return parsed_configs
        except yaml.YAMLError:
            pass # Ø§Ú¯Ø± ÛŒÙ…Ù„ Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ Ù…ÛŒâ€ŒØ±ÙˆØ¯

        # 3. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† HTML
        if '<html>' in content.lower() or url.endswith(('.html', '.htm')):
            return parse_html_content(content)

        # 4. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ú©Ù„ Ù…Ø­ØªÙˆØ§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Base64
        decoded_content = _decode_padded_b64(content)
        if decoded_content:
            content = decoded_content
            
        # 5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§ Regex Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø±Ø§Ù‡ Ø­Ù„
        pattern = r'(' + '|'.join(p for p in VALID_PREFIXES) + r')[^\s\'"<>]+'
        return set(re.findall(pattern, content))

    except requests.RequestException as e:
        print(f"   - Ù‡Ø´Ø¯Ø§Ø±: Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ {url[:50]}... Ø¯Ù„ÛŒÙ„: {e}")
        return set()
    except Exception as e:
        print(f"   - Ù‡Ø´Ø¯Ø§Ø±: Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ {url[:50]}... Ø¯Ù„ÛŒÙ„: {e}")
        return set()

# =================================================================================
# === CORE FUNCTIONS (ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ - Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ===
# =================================================================================
# ØªØ§Ø¨Ø¹â€ŒÙ‡Ø§ÛŒ get_static_sources, discover_dynamic_sources, test_config_via_api, 
# validate_and_categorize_configs, generate_clash_subscription Ùˆ main
# Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ù†Ø¯ØŒ Ù…Ú¯Ø± Ø§ÛŒÙ†Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªÙˆØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯.
# Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ú©Ø¯ Ú©Ø§Ù…Ù„ Ø¢ÙˆØ±Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.

def get_static_sources() -> list:
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ù†Ø§Ø¨Ø¹ Ø«Ø§Ø¨Øª Ø§Ø² ÙØ§ÛŒÙ„ sources.json"""
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f).get("static", [])
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def discover_dynamic_sources() -> list:
    """Ú©Ø´Ù Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ§Ø²Ù‡ Ø§Ø² GitHub"""
    if not GITHUB_PAT:
        print("âš ï¸ ØªÙˆÚ©Ù† Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ (GH_PAT) ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾ÙˆÛŒØ§ ØµØ±Ù Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return []
    
    print("ğŸ” Ú©Ø´Ù Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ§Ø²Ù‡ Ø§Ø² GitHub...")
    auth = Auth.Token(GITHUB_PAT)
    g = Github(auth=auth, timeout=20)
    
    freshness_threshold = datetime.now(timezone.utc) - timedelta(hours=GITHUB_FRESHNESS_HOURS)
    dynamic_sources = set()

    for query in GITHUB_SEARCH_QUERIES:
        try:
            repos = g.search_repositories(query=f'{query} language:text', sort='updated', order='desc')
            
            for repo in repos:
                if repo.updated_at < freshness_threshold or len(dynamic_sources) >= GITHUB_SEARCH_LIMIT:
                    break 
                try:
                    contents = repo.get_contents("")
                    for content_file in contents:
                        if content_file.type == 'file' and content_file.name.lower().endswith(('.txt', '.md', '.yaml', '.yml', '.json')):
                            dynamic_sources.add(content_file.download_url)
                except GithubException:
                    continue
            if len(dynamic_sources) >= GITHUB_SEARCH_LIMIT: break
        except GithubException as e:
            print(f"   - Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨: {e}")
            break
    
    print(f"âœ… {len(dynamic_sources)} Ù…Ù†Ø¨Ø¹ Ù¾ÙˆÛŒØ§ÛŒ ØªØ§Ø²Ù‡ Ú©Ø´Ù Ø´Ø¯.")
    return list(dynamic_sources)

def test_config_via_api(config_str: str) -> dict:
    """ØªØ³Øª Ù¾ÛŒÙ†Ú¯ ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ API Ø®Ø§Ø±Ø¬ÛŒ."""
    try:
        parsed = urlparse(config_str)
        host = parsed.hostname
        port = parsed.port
        
        if parsed.scheme == 'vmess':
            decoded = json.loads(_decode_padded_b64(config_str.replace("vmess://", "")))
            host, port = decoded['add'], int(decoded['port'])
        
        if not port:
            port = {'ss': 8443, 'trojan': 443, 'vless': 443}.get(parsed.scheme, 443)
            
        response = requests.post(
            SPEED_TEST_API_ENDPOINT, 
            json={'host': host, 'port': port}, 
            headers={'Content-Type': 'application/json'}, 
            timeout=REQUEST_TIMEOUT
        )
        if response.status_code == 200:
            return {'config_str': config_str, 'ping': response.json().get('ping', 9999)}
        return {'config_str': config_str, 'ping': 9999}
    except Exception:
        return {'config_str': config_str, 'ping': 9999}

def validate_and_categorize_configs(configs: set) -> dict:
    """Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ø³ØªÙ‡ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² (Xray ÛŒØ§ Sing-box) Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    categorized = {'xray': set(), 'singbox_only': set()}
    for cfg in configs:
        try:
            parsed = urlparse(cfg)
            query_params = dict(parse_qsl(parsed.query))
            if parsed.scheme in ('hysteria2', 'hy2', 'tuic') or query_params.get('security') == 'reality':
                categorized['singbox_only'].add(cfg)
            else:
                categorized['xray'].add(cfg)
        except Exception:
            continue
    return categorized

def generate_clash_subscription(configs: list) -> str | None:
    """ÛŒÚ© ÙØ§ÛŒÙ„ Ø§Ø´ØªØ±Ø§Ú© Ø¨Ø§ ÙØ±Ù…Øª YAML Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Clash ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    proxies = []
    used_names = set()
    for config_str in configs:
        try:
            protocol = config_str.split("://")[0]
            if protocol not in ('vless', 'vmess', 'trojan', 'ss'): continue
            
            url = urlparse(config_str)
            if 'reality' in url.query.lower(): continue

            name = unquote(url.fragment) if url.fragment else url.hostname
            original_name = name
            count = 1
            while name in used_names:
                name = f"{original_name}_{count}"
                count += 1
            used_names.add(name)

            proxy = {'name': name, 'type': protocol, 'server': url.hostname, 'port': int(url.port)}
            
            if protocol == 'vless':
                if not url.username: raise ValueError("VLESS config missing UUID")
                params = dict(parse_qsl(url.query))
                proxy.update({'uuid': url.username, 'tls': params.get('security') == 'tls', 'network': params.get('type', 'tcp'), 'servername': params.get('sni', url.hostname), 'skip-cert-verify': True})
                if proxy.get('network') == 'ws': 
                    proxy['ws-opts'] = {'path': params.get('path', '/'), 'headers': {'Host': params.get('host', url.hostname)}}
            elif protocol == 'vmess':
                decoded = json.loads(_decode_padded_b64(config_str.replace("vmess://", "")))
                if not decoded.get('id'): raise ValueError("VMESS config missing ID")
                proxy.update({
                    'server': decoded.get('add'), 'port': int(decoded.get('port')), 'uuid': decoded.get('id'), 
                    'alterId': decoded.get('aid'), 'cipher': decoded.get('scy', 'auto'), 
                    'tls': decoded.get('tls') == 'tls', 'network': decoded.get('net', 'tcp'), 
                    'servername': decoded.get('sni', decoded.get('add')), 'skip-cert-verify': True
                })
                if proxy.get('network') == 'ws':
                    proxy['ws-opts'] = {'path': decoded.get('path', '/'), 'headers': {'Host': decoded.get('host', decoded.get('add'))}}
            elif protocol == 'trojan':
                if not url.username: raise ValueError("Trojan config missing password")
                params = dict(parse_qsl(url.query))
                proxy.update({'password': url.username, 'sni': params.get('sni', url.hostname), 'skip-cert-verify': True})
            elif protocol == 'ss':
                cred = _decode_padded_b64(unquote(url.username)).split(':')
                if len(cred) < 2 or not cred[0] or not cred[1]: raise ValueError("SS config malformed credentials")
                proxy.update({'cipher': cred[0], 'password': cred[1]})
            
            proxies.append(proxy)
        except Exception:
            continue
            
    if not proxies: return None
    
    clash_config = {'proxies': proxies}
    return yaml.dump(clash_config, allow_unicode=True, sort_keys=False)

def main():
    print(f"ğŸš€ V2V Scraper v5.4 - Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ú†Ù†Ø¯ ÙØ±Ù…ØªÛŒ...")
    start_time = time.time()
    
    static_sources = get_static_sources()
    dynamic_sources = discover_dynamic_sources()
    all_sources = list(set(static_sources + dynamic_sources))
    print(f"ğŸ“¡ Ù…Ø¬Ù…ÙˆØ¹ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡: {len(all_sources)} ( {len(static_sources)} Ø«Ø§Ø¨Øª + {len(dynamic_sources)} Ù¾ÙˆÛŒØ§ )")
    
    print("\nğŸšš Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ (Ø¨Ø§ Ù…ÙˆØªÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯)...")
    raw_configs = set()
    with ThreadPoolExecutor(max_workers=30) as executor:
        for result in executor.map(fetch_and_parse_url, all_sources):
            raw_configs.update(result)
    print(f"ğŸ“¦ {len(raw_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")

    if not raw_configs:
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
        with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f: json.dump({'xray': [], 'singbox': []}, f)
        return

    print("\nğŸ”¬ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§ÙˆÙ„ÛŒÙ‡...")
    categorized_configs = validate_and_categorize_configs(raw_configs)
    xray_compatible_set = categorized_configs['xray']
    all_unique_configs = list(xray_compatible_set.union(categorized_configs['singbox_only']))
    print(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {len(categorized_configs['xray'])} Ú©Ø§Ù†ÙÛŒÚ¯ Xray | {len(categorized_configs['singbox_only'])} Ú©Ø§Ù†ÙÛŒÚ¯ ÙÙ‚Ø· Sing-box")
    
    configs_to_test = all_unique_configs
    if len(all_unique_configs) > MAX_CONFIGS_TO_TEST:
        print(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ ({len(all_unique_configs)}) Ø²ÛŒØ§Ø¯ Ø§Ø³Øª. {MAX_CONFIGS_TO_TEST} Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        configs_to_test = all_unique_configs[:MAX_CONFIGS_TO_TEST]

    print(f"\nğŸƒâ€â™‚ï¸ Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ø³Ø±Ø¹Øª {len(configs_to_test)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯...")
    all_fast_configs_results = []
    with ThreadPoolExecutor(max_workers=30) as executor:
        future_to_config = {executor.submit(test_config_via_api, cfg): cfg for cfg in configs_to_test}
        for future in as_completed(future_to_config):
            result = future.result()
            if result['ping'] < MAX_PING_THRESHOLD:
                all_fast_configs_results.append(result)

    print(f"âš¡ {len(all_fast_configs_results)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø±ÛŒØ¹ (Ø²ÛŒØ± {MAX_PING_THRESHOLD}ms) Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ ÛŒØ§ÙØª Ø´Ø¯.")
    all_fast_configs_results.sort(key=lambda x: x['ping'])

    final_xray = []
    for result in all_fast_configs_results:
        if len(final_xray) >= TARGET_CONFIGS_PER_CORE:
            break
        if result['config_str'] in xray_compatible_set:
            final_xray.append(result['config_str'])
            
    final_singbox = [res['config_str'] for res in all_fast_configs_results[:TARGET_CONFIGS_PER_CORE]]

    print("\nğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")
    output_for_frontend = {
        'xray': final_xray,
        'singbox': final_singbox
    }
    with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_for_frontend, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_JSON_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    
    clash_content = generate_clash_subscription(final_xray)
    if clash_content:
        with open(OUTPUT_CLASH_FILE, 'w', encoding='utf-8') as f:
            f.write(clash_content)
        print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_CLASH_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø´ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    else:
        print(f"âš ï¸ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ú©Ù„Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙØ§ÛŒÙ„ '{OUTPUT_CLASH_FILE}' Ø¢Ù¾Ø¯ÛŒØª Ù†Ø´Ø¯.")

    elapsed_time = time.time() - start_time
    print("\nğŸ‰ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    print("="*30)
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
    print(f"   - Xray Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ: {len(final_xray)}")
    print(f"   - Sing-box Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ: {len(final_singbox)}")
    print(f"   - Ù…Ø¬Ù…ÙˆØ¹ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(all_fast_configs_results)}")
    print(f"   - Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {elapsed_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
    print("="*30)

if __name__ == "__main__":
    main()
