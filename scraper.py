# -*- coding: utf-8 -*-

import requests
import base64
import os
import json
import re
import time
import yaml
import socket
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qsl, unquote, urlencode, quote
from collections import defaultdict
from github import Github, Auth, GithubException
from bs4 import BeautifulSoup

# =================================================================================
# === CONFIGURATION (ØªÙ†Ø¸ÛŒÙ…Ø§Øª) ===
# =================================================================================

SOURCES_FILE = "sources.json"
OUTPUT_JSON_FILE = "all_live_configs.json"
OUTPUT_CLASH_FILE = "clash_subscription.yaml"
VALID_PREFIXES = ('vless://', 'vmess://', 'trojan://', 'ss://', 'hysteria2://', 'hy2://', 'tuic://')
HEADERS = {
    'User-Agent': 'V2V-Scraper/v6.1-Refined',
    'Cache-Control': 'no-cache', 'Pragma': 'no-cache', 'Expires': '0'
}

GITHUB_PAT = os.environ.get('GH_PAT')
GITHUB_SEARCH_LIMIT = 75
GITHUB_FRESHNESS_HOURS = 240
GITHUB_SEARCH_QUERIES = [
    'v2ray subscription', 'vless subscription', 'proxy subscription',
    'vmess config', 'trojan config', 'clash subscription'
]

MAX_CONFIGS_TO_TEST = 3000
MAX_PING_THRESHOLD = 2000
TARGET_CONFIGS_PER_CORE = 500
REQUEST_TIMEOUT = 10
TCP_TEST_TIMEOUT = 5
MAX_NAME_LENGTH = 40  # Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯

# --- Ø³ÛŒØ³ØªÙ… Ø³Ù‡Ù…ÛŒÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¶Ù…ÛŒÙ† ØªÙ†ÙˆØ¹ Ù¾Ø±ÙˆØªÚ©Ù„ ---
PROTOCOL_QUOTAS = {
    'vless': 0.45,  # 45% of target
    'vmess': 0.45,  # 45% of target
    'trojan': 0.05, # 5% of target
    'ss': 0.05      # 5% of target
}

if GITHUB_PAT:
    HEADERS['Authorization'] = f'token {GITHUB_PAT}'

# =================================================================================
# === HELPER & PARSING FUNCTIONS (ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø±) ===
# =================================================================================

def _decode_padded_b64(encoded_str: str) -> str:
    if not encoded_str: return ""
    encoded_str = encoded_str.strip().replace('\n', '').replace('\r', '').replace(' ', '')
    padded_str = encoded_str + '=' * (-len(encoded_str) % 4)
    try:
        return base64.b64decode(padded_str).decode('utf-8')
    except Exception:
        for encoding in ['latin1', 'ascii', 'utf-16']:
            try: return base64.b64decode(padded_str).decode(encoding)
            except Exception: continue
        return ""

def _is_valid_config_format(config_str: str) -> bool:
    try:
        parsed = urlparse(config_str)
        return (parsed.scheme in [p.replace('://', '') for p in VALID_PREFIXES] and parsed.hostname and len(config_str) > 20 and '://' in config_str)
    except Exception: return False

def shorten_config_name(config_str: str) -> str:
    """
    Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯ Ø±Ø§ Ø¯Ø± URI Ú©ÙˆØªØ§Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¯Ø± Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ØªØ± Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.
    """
    try:
        # --- Ø±Ø³ÛŒØ¯Ú¯ÛŒ Ø¨Ù‡ VMess ---
        if config_str.startswith('vmess://'):
            encoded_part = config_str[8:]
            try:
                decoded_json_str = _decode_padded_b64(encoded_part)
                vmess_data = json.loads(decoded_json_str)
                name = vmess_data.get('ps', '')
                if len(name) > MAX_NAME_LENGTH:
                    vmess_data['ps'] = name[:MAX_NAME_LENGTH-3] + '...'
                    new_json_str = json.dumps(vmess_data, separators=(',', ':'))
                    new_encoded_part = base64.b64encode(new_json_str.encode('utf-8')).decode('utf-8').replace('=', '')
                    return 'vmess://' + new_encoded_part
                return config_str
            except Exception:
                return config_str

        # --- Ø±Ø³ÛŒØ¯Ú¯ÛŒ Ø¨Ù‡ Ø³Ø§ÛŒØ± Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± URI ---
        else:
            if '#' not in config_str:
                return config_str
            
            base_part, name_part = config_str.split('#', 1)
            decoded_name = unquote(name_part)
            
            if len(decoded_name) > MAX_NAME_LENGTH:
                shortened_name = decoded_name[:MAX_NAME_LENGTH-3] + '...'
                return base_part + '#' + quote(shortened_name)
            
            return config_str

    except Exception:
        return config_str # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ØŒ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ ØªØ§ Ø§Ø² Ú©Ø§Ø± Ù†ÛŒÙØªØ¯

def parse_subscription_content(content: str) -> set:
    configs = set()
    try:
        decoded_content = _decode_padded_b64(content)
        if decoded_content and decoded_content.count("://") > content.count("://"): content = decoded_content
    except Exception: pass
    
    pattern = r'(' + '|'.join(re.escape(p) for p in VALID_PREFIXES) + r')[^\s\'"<>\[\]{}()]*'
    matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
    for match in matches:
        clean_match = match.strip().strip('\'"')
        if _is_valid_config_format(clean_match): configs.add(clean_match)
    return configs

def fetch_and_parse_url(url: str) -> set:
    try:
        response = requests.get(url, timeout=REQUEST_TIMEOUT, headers=HEADERS)
        response.raise_for_status()
        return parse_subscription_content(response.text)
    except (requests.RequestException, Exception): return set()

def get_static_sources() -> list:
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f: return json.load(f).get("static", [])
    except (FileNotFoundError, json.JSONDecodeError): return []

def discover_dynamic_sources() -> list:
    if not GITHUB_PAT: return []
    g = Github(auth=Auth.Token(GITHUB_PAT), timeout=20)
    freshness_threshold = datetime.now(timezone.utc) - timedelta(hours=GITHUB_FRESHNESS_HOURS)
    dynamic_sources = set()
    for query in GITHUB_SEARCH_QUERIES:
        try:
            repos = g.search_repositories(query=f'{query} language:text', sort='updated', order='desc')
            for repo in repos:
                if repo.updated_at < freshness_threshold or len(dynamic_sources) >= GITHUB_SEARCH_LIMIT: break
                try:
                    for content_file in repo.get_contents(""):
                        if content_file.type == 'file' and content_file.name.lower().endswith(('.txt', '.md')):
                            dynamic_sources.add(content_file.download_url)
                except GithubException: continue
                if len(dynamic_sources) >= GITHUB_SEARCH_LIMIT: break
        except GithubException: continue
    return list(dynamic_sources)

def validate_and_categorize_configs(configs: set) -> dict:
    categorized = {'xray': set(), 'singbox_only': set()}
    for cfg in configs:
        if not _is_valid_config_format(cfg): continue
        try:
            parsed = urlparse(cfg)
            query_params = dict(parse_qsl(parsed.query))
            if (parsed.scheme in ('hysteria2', 'hy2', 'tuic') or query_params.get('security') == 'reality'):
                categorized['singbox_only'].add(cfg)
            else: categorized['xray'].add(cfg)
        except Exception: categorized['xray'].add(cfg)
    return categorized

def generate_clash_subscription(configs: list) -> str | None:
    proxies = []
    used_names = set()
    for config_str in configs:
        try:
            protocol = config_str.split("://")[0]
            if protocol not in ('vless', 'vmess', 'trojan', 'ss'): continue
            url = urlparse(config_str)
            if not url.hostname or not url.port or 'reality' in config_str.lower(): continue
            name = unquote(url.fragment) if url.fragment else url.hostname
            original_name, count = name[:50], 1
            while name in used_names:
                name = f"{original_name}_{count}"; count += 1
            used_names.add(name)
            proxy = {'name': name, 'type': protocol, 'server': url.hostname, 'port': int(url.port)}
            if protocol == 'vless':
                if not url.username: continue
                params = dict(parse_qsl(url.query))
                proxy.update({'uuid': url.username, 'tls': params.get('security') == 'tls', 'network': params.get('type', 'tcp'), 'servername': params.get('sni', url.hostname), 'skip-cert-verify': True})
                if proxy.get('network') == 'ws': proxy['ws-opts'] = {'path': params.get('path', '/'), 'headers': {'Host': params.get('host', url.hostname)}}
            elif protocol == 'vmess':
                decoded = json.loads(_decode_padded_b64(config_str.replace("vmess://", "")))
                if not decoded.get('id'): continue
                proxy.update({'server': decoded.get('add'), 'port': int(decoded.get('port')), 'uuid': decoded.get('id'), 'alterId': decoded.get('aid', 0), 'cipher': decoded.get('scy', 'auto'), 'tls': decoded.get('tls') == 'tls', 'network': decoded.get('net', 'tcp'), 'servername': decoded.get('sni', decoded.get('add')), 'skip-cert-verify': True})
                if proxy.get('network') == 'ws': proxy['ws-opts'] = {'path': decoded.get('path', '/'), 'headers': {'Host': decoded.get('host', decoded.get('add'))}}
            elif protocol == 'trojan':
                if not url.username: continue
                params = dict(parse_qsl(url.query))
                proxy.update({'password': url.username, 'sni': params.get('sni', url.hostname), 'skip-cert-verify': True})
            elif protocol == 'ss':
                cred = _decode_padded_b64(unquote(url.username)).split(':')
                if len(cred) < 2 or not cred[0] or not cred[1]: continue
                proxy.update({'cipher': cred[0], 'password': cred[1]})
            proxies.append(proxy)
        except Exception: continue
    if not proxies: return None
    return yaml.dump({'proxies': proxies}, allow_unicode=True, sort_keys=False, indent=2)

# =================================================================================
# === DIRECT TCP PING TEST (ØªØ³Øª Ù¾ÛŒÙ†Ú¯ Ù…Ø³ØªÙ‚ÛŒÙ…) [IMPROVED] ===
# =================================================================================

def test_config_direct_tcp(config_str: str) -> dict:
    host, port = None, None
    try:
        parsed = urlparse(config_str)
        if parsed.scheme == 'vmess':
            decoded = json.loads(_decode_padded_b64(config_str.replace("vmess://", "")))
            host, port = decoded.get('add'), int(decoded.get('port', 443))
        else:
            host, port = parsed.hostname, parsed.port

        if not host: return {'config_str': config_str, 'ping': 9999, 'error': 'Host not found'}
        if not port: port = {'ss': 8443, 'trojan': 443, 'vless': 443}.get(parsed.scheme, 443)

        addr_infos = socket.getaddrinfo(host, port, 0, socket.SOCK_STREAM)
        for family, socktype, proto, _, sockaddr in addr_infos:
            try:
                with socket.socket(family, socktype, proto) as s:
                    s.settimeout(TCP_TEST_TIMEOUT)
                    start_time = time.monotonic()
                    s.connect(sockaddr)
                    end_time = time.monotonic()
                    ping = int((end_time - start_time) * 1000)
                    return {'config_str': config_str, 'ping': ping}
            except (socket.error, socket.timeout):
                continue
        return {'config_str': config_str, 'ping': 9999, 'error': 'All connection attempts failed'}
    except Exception as e:
        return {'config_str': config_str, 'ping': 9999, 'error': str(e)}

# =================================================================================
# === MAIN EXECUTION (Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ) ===
# =================================================================================

def main():
    print(f"ğŸš€ V2V Scraper v6.1 - Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ ØªØ³Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ùˆ ØªÙˆØ§Ø²Ù† Ù¾Ø±ÙˆØªÚ©Ù„...")
    start_time = time.time()
    
    all_sources = list(set(get_static_sources() + discover_dynamic_sources()))
    print(f"ğŸ“¡ Ù…Ø¬Ù…ÙˆØ¹ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡: {len(all_sources)}")
    if not all_sources:
        print("âŒ Ù‡ÛŒÚ† Ù…Ù†Ø¨Ø¹ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."); return

    print("\nğŸšš Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§...")
    raw_configs = set()
    with ThreadPoolExecutor(max_workers=30) as executor:
        for result in executor.map(fetch_and_parse_url, all_sources):
            raw_configs.update(result)
    print(f"ğŸ“¦ {len(raw_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")
    if not raw_configs:
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."); return

    print("\nğŸ”¬ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ...")
    categorized_configs = validate_and_categorize_configs(raw_configs)
    xray_compatible_set = categorized_configs['xray']
    singbox_only_set = categorized_configs['singbox_only']
    print(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {len(xray_compatible_set)} Ú©Ø§Ù†ÙÛŒÚ¯ Xray | {len(singbox_only_set)} Ú©Ø§Ù†ÙÛŒÚ¯ ÙÙ‚Ø· Sing-box")
    
    all_unique_configs = list(xray_compatible_set.union(singbox_only_set))
    configs_to_test = all_unique_configs[:MAX_CONFIGS_TO_TEST]
    print(f"\nğŸƒâ€â™‚ï¸ Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ø³Ø±Ø¹Øª {len(configs_to_test)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø§ Ø§ØªØµØ§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… TCP...")
    
    fast_configs_results = []
    with ThreadPoolExecutor(max_workers=50) as executor:
        for result in executor.map(test_config_direct_tcp, configs_to_test):
            if result.get('ping', 9999) < MAX_PING_THRESHOLD:
                fast_configs_results.append(result)

    print(f"âš¡ {len(fast_configs_results)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø±ÛŒØ¹ (Ø²ÛŒØ± {MAX_PING_THRESHOLD}ms) ÛŒØ§ÙØª Ø´Ø¯.")
    fast_configs_results.sort(key=lambda x: x['ping'])
    
    print("\nâš–ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆØ§Ø²Ù† Ø¨ÛŒÙ† Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ...")
    fast_xray_compatible = [res for res in fast_configs_results if res['config_str'] in xray_compatible_set]
    fast_singbox_only = [res['config_str'] for res in fast_configs_results if res['config_str'] in singbox_only_set]
    
    grouped_xray_fast = defaultdict(list)
    for res in fast_xray_compatible:
        proto = res['config_str'].split("://")[0]
        grouped_xray_fast[proto].append(res['config_str'])

    balanced_xray_list = []
    for proto, quota_percent in PROTOCOL_QUOTAS.items():
        quota_size = int(TARGET_CONFIGS_PER_CORE * quota_percent)
        balanced_xray_list.extend(grouped_xray_fast.get(proto, [])[:quota_size])
    
    if len(balanced_xray_list) < TARGET_CONFIGS_PER_CORE:
        all_fast_xray_uris = [res['config_str'] for res in fast_xray_compatible]
        for cfg in all_fast_xray_uris:
            if len(balanced_xray_list) >= TARGET_CONFIGS_PER_CORE: break
            if cfg not in balanced_xray_list:
                balanced_xray_list.append(cfg)

    final_xray = balanced_xray_list[:TARGET_CONFIGS_PER_CORE]
    
    final_singbox = fast_singbox_only
    remaining_needed = TARGET_CONFIGS_PER_CORE - len(final_singbox)
    if remaining_needed > 0:
        xray_configs_for_singbox = [cfg for cfg in [res['config_str'] for res in fast_xray_compatible] if cfg not in final_xray]
        final_singbox.extend(xray_configs_for_singbox[:remaining_needed])
    final_singbox = final_singbox[:TARGET_CONFIGS_PER_CORE]

    # <<<--- START: Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ --->>>
    print("\nğŸ“ Ø¯Ø± Ø­Ø§Ù„ Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±...")
    final_xray_shortened = [shorten_config_name(cfg) for cfg in final_xray]
    final_singbox_shortened = [shorten_config_name(cfg) for cfg in final_singbox]
    # <<<--- END: Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ --->>>

    print("\nğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")
    output_for_frontend = {'xray': final_xray_shortened, 'singbox': final_singbox_shortened, 'timestamp': int(time.time())}
    with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f: json.dump(output_for_frontend, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_JSON_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    
    clash_content = None
    if final_xray_shortened: # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„ÛŒØ³Øª Ø¨Ø§ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ø´Ø¯Ù‡
        clash_content = generate_clash_subscription(final_xray_shortened)
    if not clash_content and xray_compatible_set:
        print("âš ï¸ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø±ÛŒØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯. ØªÙ„Ø§Ø´ Ø¨Ø§ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ù†Ø´Ø¯Ù‡...")
        # Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù†Ø§Ù…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„Øª Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù†ÛŒØ² Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        untested_clash_configs = [shorten_config_name(cfg) for cfg in list(xray_compatible_set)[:100]]
        clash_content = generate_clash_subscription(untested_clash_configs)

    if clash_content:
        with open(OUTPUT_CLASH_FILE, 'w', encoding='utf-8') as f: f.write(clash_content)
        print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_CLASH_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    else:
        print(f"âŒ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ú©Ù„Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    
    elapsed_time = time.time() - start_time
    print("\nğŸ‰ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    print("="*50)
    print(f"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬: | Xray: {len(final_xray_shortened)} | Sing-box: {len(final_singbox_shortened)} | Ø²Ù…Ø§Ù†: {elapsed_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
    print("="*50)

if __name__ == "__main__":
    main()
