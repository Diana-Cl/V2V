# -*- coding: utf-8 -*-

import requests
import base64
import os
import json
import re
import time
import yaml
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qsl, unquote, urlencode
from github import Github, Auth, GithubException

# =================================================================================
# === CONFIGURATION (ØªÙ†Ø¸ÛŒÙ…Ø§Øª) ===
# =================================================================================

# --- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ
SOURCES_FILE = "sources.json"
OUTPUT_JSON_FILE = "all_live_configs.json"
OUTPUT_CLASH_FILE = "clash_subscription.yaml"

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
VALID_PREFIXES = ('vless://', 'vmess://', 'trojan://', 'ss://', 'hysteria2://', 'hy2://', 'tuic://')

# --- FIX: Anti-Cache Headers added to solve the caching problem ---
HEADERS = {
    'User-Agent': 'V2V-Scraper/v5.3-Flexible',
    'Cache-Control': 'no-cache, no-store, must-revalidate',
    'Pragma': 'no-cache',
    'Expires': '0'
}

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨
GITHUB_PAT = os.environ.get('GH_PAT')
GITHUB_SEARCH_LIMIT = 50
GITHUB_FRESHNESS_HOURS = 120 # (5 Ø±ÙˆØ²)
GITHUB_SEARCH_QUERIES = ['v2ray subscription', 'vless subscription', 'proxy subscription']

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ³Øª Ø³Ø±Ø¹Øª Ùˆ Ú©ÛŒÙÛŒØªâ€ŒØ³Ù†Ø¬ÛŒ
SPEED_TEST_API_ENDPOINT = 'https://v2-v.vercel.app/api/proxy'
MAX_CONFIGS_TO_TEST = 2000
# --- CHANGE: Increased ping threshold for more flexibility ---
MAX_PING_THRESHOLD = 5000 # (5 Ø«Ø§Ù†ÛŒÙ‡) - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ
TARGET_CONFIGS_PER_CORE = 500
REQUEST_TIMEOUT = 10

if GITHUB_PAT:
    HEADERS['Authorization'] = f'token {GITHUB_PAT}'

# =================================================================================
# === HELPER FUNCTIONS (ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ) ===
# =================================================================================

def _decode_padded_b64(encoded_str: str) -> str:
    """
    ÛŒÚ© Ø±Ø´ØªÙ‡ Base64 Ø±Ø§ Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù† padding Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    padded_str = encoded_str + '=' * (-len(encoded_str) % 4)
    return base64.b64decode(padded_str).decode('utf-8')

# =================================================================================
# === CORE FUNCTIONS (ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ) ===
# =================================================================================

def get_static_sources() -> list:
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ù†Ø§Ø¨Ø¹ Ø«Ø§Ø¨Øª Ø§Ø² ÙØ§ÛŒÙ„ sources.json"""
    try:
        with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f).get("static", [])
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def discover_dynamic_sources() -> list:
    """Ú©Ø´Ù Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ§Ø²Ù‡ Ø§Ø² GitHub"""
    if not GITHUB_PAT:
        print("âš ï¸ ØªÙˆÚ©Ù† Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ (GH_PAT) ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾ÙˆÛŒØ§ ØµØ±Ù Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return []
    
    print("ğŸ” Ú©Ø´Ù Ù…Ù†Ø§Ø¨Ø¹ Ù¾ÙˆÛŒØ§ Ùˆ ØªØ§Ø²Ù‡ Ø§Ø² GitHub...")
    auth = Auth.Token(GITHUB_PAT)
    g = Github(auth=auth, timeout=20)
    
    freshness_threshold = datetime.now(timezone.utc) - timedelta(hours=GITHUB_FRESHNESS_HOURS)
    dynamic_sources = set()

    for query in GITHUB_SEARCH_QUERIES:
        try:
            repos = g.search_repositories(query=f'{query} language:text', sort='updated', order='desc')
            
            for repo in repos:
                if repo.updated_at < freshness_threshold or len(dynamic_sources) >= GITHUB_SEARCH_LIMIT:
                    break 
                try:
                    contents = repo.get_contents("")
                    for content_file in contents:
                        if content_file.type == 'file' and content_file.name.lower().endswith(('.txt', '.md', '.yaml', '.yml', '.json')):
                            dynamic_sources.add(content_file.download_url)
                except GithubException:
                    continue
            if len(dynamic_sources) >= GITHUB_SEARCH_LIMIT: break
        except GithubException as e:
            print(f"   - Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨: {e}")
            break
    
    print(f"âœ… {len(dynamic_sources)} Ù…Ù†Ø¨Ø¹ Ù¾ÙˆÛŒØ§ÛŒ ØªØ§Ø²Ù‡ Ú©Ø´Ù Ø´Ø¯.")
    return list(dynamic_sources)

def parse_structured_json(content: dict) -> set:
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ (Ù…Ø§Ù†Ù†Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯ Sing-box)
    """
    configs = set()
    if 'outbounds' in content and isinstance(content['outbounds'], list):
        for outbound in content['outbounds']:
            try:
                protocol = outbound.get('protocol') or outbound.get('type')
                if protocol == 'vless' and 'server' in outbound and 'uuid' in outbound:
                    server = outbound['server']
                    port = outbound.get('server_port', 443)
                    uuid = outbound['uuid']
                    name = outbound.get('tag', server)
                    
                    tls_settings = outbound.get('tls', {})
                    transport_settings = outbound.get('transport', {})
                    
                    security = 'none'
                    if tls_settings.get('enabled'):
                        security = 'tls'
                        if tls_settings.get('reality', {}).get('enabled'):
                            security = 'reality'
                    
                    params = {
                        'security': security,
                        'sni': tls_settings.get('server_name', server),
                        'type': transport_settings.get('type', 'tcp'),
                        'path': transport_settings.get('path', '/'),
                        'host': transport_settings.get('headers', {}).get('Host', server)
                    }
                    
                    if security == 'reality':
                        params['pbk'] = tls_settings['reality']['public_key']
                        params['sid'] = tls_settings['reality'].get('short_id', '')

                    query_string = urlencode({k: v for k, v in params.items() if v and k != 'security' or v != 'none'})
                    config_str = f"vless://{uuid}@{server}:{port}?{query_string}#{unquote(name)}"
                    configs.add(config_str)
            except (KeyError, TypeError):
                continue
    return configs

def fetch_and_parse_url(url: str) -> set:
    """
    Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² ÛŒÚ© URL Ø¨Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ú©Ø´.
    """
    try:
        # The global HEADERS with anti-cache directives is used here
        response = requests.get(url, timeout=15, headers=HEADERS)
        response.raise_for_status()
        content = response.text
        try:
            json_content = json.loads(content)
            parsed_configs = parse_structured_json(json_content)
            if parsed_configs:
                return parsed_configs
        except json.JSONDecodeError:
            pass
        
        try:
            decoded_content = _decode_padded_b64(content)
            content = decoded_content
        except Exception:
            pass
        
        pattern = r'(' + '|'.join(p for p in VALID_PREFIXES) + r')[^\s\'"<>]+'
        return set(re.findall(pattern, content))
    except requests.RequestException:
        return set()

def test_config_via_api(config_str: str) -> dict:
    """ØªØ³Øª Ù¾ÛŒÙ†Ú¯ ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ API Ø®Ø§Ø±Ø¬ÛŒ."""
    try:
        parsed = urlparse(config_str)
        host = parsed.hostname
        port = parsed.port
        
        if parsed.scheme == 'vmess':
            decoded = json.loads(_decode_padded_b64(config_str.replace("vmess://", "")))
            host, port = decoded['add'], int(decoded['port'])
        
        if not port:
            port = {'ss': 8443, 'trojan': 443, 'vless': 443}.get(parsed.scheme, 443)
            
        response = requests.post(
            SPEED_TEST_API_ENDPOINT, 
            json={'host': host, 'port': port}, 
            headers={'Content-Type': 'application/json'}, 
            timeout=REQUEST_TIMEOUT
        )
        if response.status_code == 200:
            return {'config_str': config_str, 'ping': response.json().get('ping', 9999)}
        return {'config_str': config_str, 'ping': 9999}
    except Exception:
        return {'config_str': config_str, 'ping': 9999}

def validate_and_categorize_configs(configs: set) -> dict:
    """Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ø³ØªÙ‡ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² (Xray ÛŒØ§ Sing-box) Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    categorized = {'xray': set(), 'singbox_only': set()}
    for cfg in configs:
        try:
            parsed = urlparse(cfg)
            if parsed.scheme in ('hysteria2', 'hy2', 'tuic') or 'reality' in parse_qsl(parsed.query):
                categorized['singbox_only'].add(cfg)
            else:
                categorized['xray'].add(cfg)
        except Exception:
            continue
    return categorized

def generate_clash_subscription(configs: list) -> str | None:
    """ÛŒÚ© ÙØ§ÛŒÙ„ Ø§Ø´ØªØ±Ø§Ú© Ø¨Ø§ ÙØ±Ù…Øª YAML Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Clash ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    proxies = []
    used_names = set()
    for config_str in configs:
        try:
            protocol = config_str.split("://")[0]
            if protocol not in ('vless', 'vmess', 'trojan', 'ss'): continue
            
            url = urlparse(config_str)
            if 'reality' in url.query.lower(): continue

            name = unquote(url.fragment) if url.fragment else url.hostname
            original_name = name
            count = 1
            while name in used_names:
                name = f"{original_name}_{count}"
                count += 1
            used_names.add(name)

            proxy = {'name': name, 'type': protocol, 'server': url.hostname, 'port': int(url.port)}
            
            if protocol == 'vless':
                if not url.username: raise ValueError("VLESS config missing UUID")
                params = dict(parse_qsl(url.query))
                proxy.update({'uuid': url.username, 'tls': params.get('security') == 'tls', 'network': params.get('type', 'tcp'), 'servername': params.get('sni', url.hostname), 'skip-cert-verify': True})
                if proxy.get('network') == 'ws': 
                    proxy['ws-opts'] = {'path': params.get('path', '/'), 'headers': {'Host': params.get('host', url.hostname)}}
            elif protocol == 'vmess':
                decoded = json.loads(_decode_padded_b64(config_str.replace("vmess://", "")))
                if not decoded.get('id'): raise ValueError("VMESS config missing ID")
                proxy.update({
                    'server': decoded.get('add'), 
                    'port': int(decoded.get('port')),
                    'uuid': decoded.get('id'), 
                    'alterId': decoded.get('aid'), 
                    'cipher': decoded.get('scy', 'auto'), 
                    'tls': decoded.get('tls') == 'tls', 
                    'network': decoded.get('net', 'tcp'), 
                    'servername': decoded.get('sni', decoded.get('add')), 
                    'skip-cert-verify': True
                })
            elif protocol == 'trojan':
                if not url.username: raise ValueError("Trojan config missing password")
                params = dict(parse_qsl(url.query))
                proxy.update({'password': url.username, 'sni': params.get('sni', url.hostname), 'skip-cert-verify': True})
            elif protocol == 'ss':
                cred = _decode_padded_b64(unquote(url.username)).split(':')
                if len(cred) < 2 or not cred[0] or not cred[1]: raise ValueError("SS config malformed credentials")
                proxy.update({'cipher': cred[0], 'password': cred[1]})
            
            proxies.append(proxy)
        except Exception as e:
            # print(f"   - Ù‡Ø´Ø¯Ø§Ø±: Ú©Ø§Ù†ÙÛŒÚ¯ {config_str[:40]}... Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø´ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø¨ÙˆØ¯. Ø¯Ù„ÛŒÙ„: {e}")
            continue
            
    if not proxies: return None
    
    clash_config = {'proxies': proxies}
    return yaml.dump(clash_config, allow_unicode=True, sort_keys=False)

# =================================================================================
# === MAIN EXECUTION (Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ) ===
# =================================================================================
def main():
    print(f"ğŸš€ V2V Scraper v5.3 - Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù†Ø¹Ø·Ù...")
    start_time = time.time()
    
    static_sources = get_static_sources()
    dynamic_sources = discover_dynamic_sources()
    all_sources = list(set(static_sources + dynamic_sources))
    print(f"ğŸ“¡ Ù…Ø¬Ù…ÙˆØ¹ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡: {len(all_sources)} ( {len(static_sources)} Ø«Ø§Ø¨Øª + {len(dynamic_sources)} Ù¾ÙˆÛŒØ§ )")
    
    print("\nğŸšš Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ (Ø¨Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ú©Ø´)...")
    raw_configs = set()
    with ThreadPoolExecutor(max_workers=30) as executor:
        for result in executor.map(fetch_and_parse_url, all_sources):
            raw_configs.update(result)
    print(f"ğŸ“¦ {len(raw_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯.")

    if not raw_configs:
        print("âŒ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
        with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f: json.dump({'xray': [], 'singbox': []}, f)
        return

    print("\nğŸ”¬ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§ÙˆÙ„ÛŒÙ‡...")
    categorized_configs = validate_and_categorize_configs(raw_configs)
    xray_compatible_set = categorized_configs['xray']
    all_unique_configs = list(xray_compatible_set.union(categorized_configs['singbox_only']))
    print(f"âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {len(categorized_configs['xray'])} Ú©Ø§Ù†ÙÛŒÚ¯ Xray | {len(categorized_configs['singbox_only'])} Ú©Ø§Ù†ÙÛŒÚ¯ ÙÙ‚Ø· Sing-box")
    
    configs_to_test = all_unique_configs
    if len(all_unique_configs) > MAX_CONFIGS_TO_TEST:
        print(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ ({len(all_unique_configs)}) Ø²ÛŒØ§Ø¯ Ø§Ø³Øª. {MAX_CONFIGS_TO_TEST} Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        configs_to_test = all_unique_configs[:MAX_CONFIGS_TO_TEST]

    print(f"\nğŸƒâ€â™‚ï¸ Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ø³Ø±Ø¹Øª {len(configs_to_test)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯...")
    all_fast_configs_results = []
    with ThreadPoolExecutor(max_workers=30) as executor:
        future_to_config = {executor.submit(test_config_via_api, cfg): cfg for cfg in configs_to_test}
        for future in as_completed(future_to_config):
            result = future.result()
            if result['ping'] < MAX_PING_THRESHOLD:
                all_fast_configs_results.append(result)

    print(f"âš¡ {len(all_fast_configs_results)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø±ÛŒØ¹ (Ø²ÛŒØ± {MAX_PING_THRESHOLD}ms) Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ ÛŒØ§ÙØª Ø´Ø¯.")
    all_fast_configs_results.sort(key=lambda x: x['ping'])

    final_xray = []
    for result in all_fast_configs_results:
        if len(final_xray) >= TARGET_CONFIGS_PER_CORE:
            break
        if result['config_str'] in xray_compatible_set:
            final_xray.append(result['config_str'])
            
    final_singbox = [res['config_str'] for res in all_fast_configs_results[:TARGET_CONFIGS_PER_CORE]]

    print("\nğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")
    output_for_frontend = {
        'xray': final_xray,
        'singbox': final_singbox
    }
    with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_for_frontend, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_JSON_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    
    clash_content = generate_clash_subscription(final_xray)
    if clash_content:
        with open(OUTPUT_CLASH_FILE, 'w', encoding='utf-8') as f:
            f.write(clash_content)
        print(f"âœ… ÙØ§ÛŒÙ„ '{OUTPUT_CLASH_FILE}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø´ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
    else:
        print(f"âš ï¸ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ú©Ù„Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙØ§ÛŒÙ„ '{OUTPUT_CLASH_FILE}' Ø¢Ù¾Ø¯ÛŒØª Ù†Ø´Ø¯.")

    elapsed_time = time.time() - start_time
    print("\nğŸ‰ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    print("="*30)
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
    print(f"   - Xray Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ: {len(final_xray)}")
    print(f"   - Sing-box Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ: {len(final_singbox)}")
    print(f"   - Ù…Ø¬Ù…ÙˆØ¹ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {len(all_fast_configs_results)}")
    print(f"   - Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: {elapsed_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
    print("="*30)

if __name__ == "__main__":
    main()
